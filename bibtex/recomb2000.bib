@inproceedings{10.1145/332306.332311,
author = {Akutsu, Tatsuya and Arimura, Hiroki and Shimozono, Shinichi},
title = {On approximation algorithms for local multiple alignment},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332311},
doi = {10.1145/332306.332311},
abstract = {This paper studies the local multiple alignment problem, which is also known as the general consensus patterns problem. Local multiple alignment is, given protein or DNA sequences, to locate a region (i.e., a substring) of fixed length from each sequence so that the score determined from the set of regions is optimized. We consider the following scoring schemes. the score indicating the average information content, the score defined by Li et al, and the sum-of-pairs scoreWe prove that multiple local alignment is NP-hard under each of these scoring schemes. In addition, we prove that multiple local alignment is APX-hard under the average information content scoring. It implies that unless P = NP there is no polynomial time algorithm whose worst case approximation error can be arbitrarily specified (precisely, a polynomial time approximation scheme). Several related theoretical results are provided.We also made computational experiments on approximation algorithms for local multiple alignment under the average information content scoring. The results suggest that the Gibbs sampling algorithm proposed by Lawrence et al. is the best.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {1–7},
numpages = {7},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332317,
author = {Akutsu, Tatsuya and Miyano, Satoru and Kuhara, Satoru},
title = {Algorithms for identifying Boolean networks and related biological networks based on matrix multiplication and fingerprint function},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332317},
doi = {10.1145/332306.332317},
abstract = {Due to the recent progress of the DNA microarray technology, a large number of gene expression profile data are being produced. How to analyze gene expression data is an important topic in computational molecular biology Several studies have been done using the Boolean network as a model of a genetic network This paper proposes efficient algorithms for identifying Boolean networks of bounded indegree and related biological networks, where identification of a Boolean network can be formalized as a problem of identifying many Boolean functions simultaneously. For the identification of a Boolean network, an O(mnD+1) time naive algorithm and a simple O(mnD) time algorithm are known, where n denotes the number of nodes, m denotes the number of examples, and D denotes the maximum indegree. This paper presents an improved O(mw-2nD + mnD+w-3) time Monte-Carlo type randomized algorithm, where w is the exponent of matrix multiplication (currently, w &lt; 2376). The algorithm is obtained by combining fast matrix multiplication with the randomized fingerprint function for string matching. Although the algorithm and its analysis are simple, the result is non-trivial and the technique can be applied to several related problems.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {8–14},
numpages = {7},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332319,
author = {Althaus, E. and Kohlbacher, O. and Lenhof, H.-P. and M\"{u}ller, P.},
title = {A combinatorial approach to protein docking with flexible side-chains},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332319},
doi = {10.1145/332306.332319},
abstract = {Rigid body docking approaches are not sufficient to predict the structure of a protein complex from the unbound (native) structures of the two proteins. Accounting for side—chain flexibility is an important step towards fully flexible protein docking. This work describes an approach that allows conformational flexibility for the side—chains while keeping the protein backbone rigid. Starting from candidates created by a rigid docking algorithm, we demangle the side—chains of the docking site, thus creating reasonable approximations of the true complex structure. These structures are ranked with respect to the binding free energy. We present two new techniques for side—chain demangling. Both approaches are based on a discrete representation of the side—chain conformational space by the use of a rotamer library. This leads to a combinatorial optimization problem. For the solution of this problem we propose a fast heuristic approach and an exact, albeit slower method using branch—&amp;—cut techniques. As a test set we use the unbound structures of three proteases and the corresponding protein inhibitors. For each of the examples the highest—ranking conformation produced was a good approximation of the true complex structure.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {15–24},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332321,
author = {Apostolico, Alberto and Bejerano, Gill},
title = {Optimal amnesic probabilistic automata or how to learn and classify proteins in linear time and space},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332321},
doi = {10.1145/332306.332321},
abstract = {Statistical modeling of sequences is a central paradigm of machine learning that finds multiple uses in computational molecular biology and many other domains. The probabilistic automata typically built in these contexts are subtended by uniform, fixed-memory Markov models. In practice, such automata tend to be unnecessarily bulky and computationally imposing both during their synthesis and use. In [8], much more compact, tree-shaped variants of probabilistic automata are built which assume an underlying Markov process of variable memory length. In [3, 4], these variants, called Probabilistic Suffix Trees (PSTs) were successfully applied to learning and prediction of protein families. The process of learning the automaton from a given training set S of sequences requires Θ (Ln2) worst-case time, where n is the total length of the sequences in S and L is the length of a longest substring of S to be considered for a candidate state in the automaton. Once the automaton is built, predicting the likelihood of a query sequence of m characters may cost time Θ (m2) in the worst case.The main contribution of this paper is to introduce automata equivalent to PSTs but having the following properties: learning the automaton takes O (n) time.prediction of a string of m symbols by the automaton takes O (m) time.Along the way, the paper presents an evolving learning sheme, and addresses notions of empirical probability and related efficient computation,possibly a by-product of more general interest.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {25–32},
numpages = {8},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332323,
author = {Bailey-Kellogg, Chris and Widge, Alik and Kelley, John J. and Berardi, Marcelo J. and Bushweller, John H. and Donald, Bruce Randall},
title = {The NOESY jigsaw: automated protein secondary structure and main-chain assignment from sparse, unassigned NMR data},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332323},
doi = {10.1145/332306.332323},
abstract = {High-throughput, data-directed computational protocols for Structural Genomics (or Proteomics) are required in order to evaluate the protein products of genes for structure and function at rates comparable to current gene-sequencing technology. This paper presents the JIGSAW algorithm, a novel high-throughput, automated approach to protein structure characterization with nuclear magnetic resonance (NMR). JIGSAW applies graph algorithms and probabilistic reasoning techniques, enforcing first-principles consistency rules in order to overcome a 5-10\% signal-to-noise ratio. It consists of two main components: (1) graph-based secondary structure pattern identification in unassigned heteronuclear NMR data, and (2) assignment of spectral peaks by probabilistic alignment of identified secondary structure elements against the primary sequence. JIGSAW's deferment of assignment until after secondary structure identification differs greatly from traditional approaches, which begin by correlating peaks among dozens of experiments. By deferring assignment, JIGSAW not only eliminates this bottleneck, it also allows the number of experiments to be reduced from dozens to four, none of which requires 13 C-labeled protein. This in turn dramatically reduces the amount and expense of wet lab molecular biology for protein expression and purification, as well as the total spectrometer time to collect data.Our results for three test proteins demonstrate that we are able to identify and align approximately 80 percent of α-helical and 60 percent of β-sheet structure. JIGSAW is very fast, running in minutes on a Pentium-class Linux workstation. This approach yields quick and reasonably accurate (as opposed to the traditional slow and extremely accurate) structure calculations, utilizing a suite of graph analysis algorithms to compensate for the data sparseness. JIGSAW could be used for quick structural assays to speed data to the biologist early in the process of investigation, and could in principle be applied in an automation-like fashion to a large fraction of the proteome.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {33–44},
numpages = {12},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332325,
author = {Batzoglou, Serafim and Berger, Bonnie and Mesirov, Jill and Lander, Eric S.},
title = {Sequencing a genome by walking with clone-end sequences (abstract): a mathematical analysis},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332325},
doi = {10.1145/332306.332325},
abstract = {One important approach to sequencing a large genome is (i) to sequence a collection of non-overlapping `seed' chosen from a genomic library of large-insert clones (such as bacterial artificial chromosome (BACs)) and then (ii) to take successive `walking' steps by selecting and sequencing minimally overlapping clones, using information such as clone-end sequences to identify the overlaps. We analyze the strategic issues involved in using this approach. We derive formulas showing how two key factors, the initial density of seed clones and the depth of the genomic library used for walking, affect the cost and time of a sequencing project—that is, the amount of redundant sequencing and the number of steps to cover the vast majority of the genome. We also discuss a variant strategy in which a second genomic library with clones having a somewhat smaller insert size is used to close gaps. This approach can dramatically decrease the amount of redundant sequencing, without affecting the rate at which the genome is covered.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {45},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332326,
author = {Batzoglou, Serafim and Pachter, Lior and Mesirov, Jill and Berger, Bonnie and Lander, Eric S.},
title = {Human and mouse gene structure: comparative analysis and application to exon prediction},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332326},
doi = {10.1145/332306.332326},
abstract = {We describe a novel analytical approach to gene recognition based on cross-species comparison We first undertook a comparison of orthologous genomic look from human and mouse, studying the extent of similarity in the number, size and sequence of exons and introns We then developed an approach for recognizing genes within such orthologous regions, by first aligning the regions using an iterative global alignment system and then identifying genes based on conservation of exonic features at aligned positions in both species The alignment and gene recognition are performed by new programs called GLASS and ROSETTA, respectively ROSETTA performed well at exact identification of coding exons in 117 orthologous pairs tested.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {46–53},
numpages = {8},
keywords = {global alignments, gene recognition, comparative genomics},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332328,
author = {Ben-Dor, Amir and Bruhn, Laurakay and Friedman, Nir and Nachman, Iftach and Schummer, Mich\`{e}l and Yakhini, Zohar},
title = {Tissue classification with gene expression profiles},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332328},
doi = {10.1145/332306.332328},
abstract = {Constantly improving gene expression profiling technologies are expected to provide understanding and insight into cancer related cellular processes. Gene expression data is also expected to significantly and in the development of efficient cancer diagnosis and classification platforms. In this work we examine two sets of gene expression data measured across sets of tumor and normal clinical samples One set consists of 2,000 genes, measured in 62 epithelial colon samples [1]. The second consists of ≈ 100,000 clones, measured in 32 ovarian samples (unpublished, extension of data set described in [26]).We examine the use of scoring methods, measuring separation of tumors from normals using individual gene expression levels. These are then coupled with high dimensional classification methods to assess the classification power of complete expression profiles. We present results of performing leave-one-out cross validation (LOOCV) experiments on the two data sets. employing SVM [8], AdaBoost [13] and a novel clustering based classification technique. As tumor samples can differ from normal samples in their cell-type composition we also perform LOOCV experiments using appropriately modified sets of genes, attempting to eliminate the resulting bias.We demonstrate success rate of at least 90\% in tumor vs normal classification, using sets of selected genes, with as well as without cellular contamination related members. These results are insensitive to the exact selection mechanism, over a certain range.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {54–64},
numpages = {11},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332346,
author = {Ben-Dor, Amir and Karp, Richard and Schwikowski, Benno and Yakhini, Zohar},
title = {Universal DNA tag systems: a combinatorial design scheme},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332346},
doi = {10.1145/332306.332346},
abstract = {Custom-designed DNA arrays offer the possibility of simultaneously monitoring thousands of hybridization reactions These arrays show great potential for many medical and scientific applications such as polymorphism analysis and genotyping. Relatively high costs are associated with the need to specifically design and synthesize problem specific arrays. Recently, an alternative approach was suggested that utilizes fixed, universal arrays. This approach presents an interesting design problem—the arrays should contain as many probes as possible, while minimizing experimental errors caused by cross-hybridization. We use a simple thermodynamic model to cast this design problem in a formal mathematical framework. Employing new combinatorial ideas, we derive an efficient construction for the design problem, and prove that our construction is near-optimal.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {65–75},
numpages = {11},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332347,
author = {Bie\'{n}kowska, Jadwiga R. and Yu, Lihua and Zarakhovich, Sophia and Rogers, Robert G. and Smith, Temple F.},
title = {Comprehensive statistical method for protein fold recognition},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332347},
doi = {10.1145/332306.332347},
abstract = {We present a protein fold recognition method that uses a comprehensive statistical interpretation of structural Hidden Markov Models (HMMs). The structure/fold recognition is done by summing the probabilities of all sequence-to-structure alignments Conventionally, Boltzmann statistics dictate that the optimal alignment can give an estimate of the lowest free energy of the sequence conformation imposed by the structural model. The alignment is optimized for a scoring function that is interpreted as a free energy of an amino acid in a structural environment. Near-optimal alignments are ignored, regardless of how likely they might be compared to the optimal alignment. Here we investigate an alternative view. A structure model can be seen as a statistical representation of an ensemble of similar structures. The optimal alignment is always the most probable, but sub-optimal alignments may have comparable probabilities. These sub-optimal alignments can be interpreted as optimal alignments to the “other” structures from the ensemble or optimal alignments under minor fluctuations in the scoring function. Summing probabilities for all alignments gives an estimate of sequence-model compatibility. We have built a set of structural HMMs for 188 protein structures, and have compared two methods for identifying the structure compatible with a sequence: by the optimal alignment probability and by the total probability. Fold recognition by total probability was 40\% more accurate than fold recognition by the optimal alignment probability.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {76–85},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332350,
author = {Bundschuh, R.},
title = {An analytic approach to significance assessment in local sequence alignment with gaps},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332350},
doi = {10.1145/332306.332350},
abstract = {A detailed study of the Smith-Waterman alignment algorithm is performed in order to find an analytical approach to the problem of assessing the statistical significance of local alignments with gaps. The significance is shown to be given in terms of an eigenvalue equation which captures the dynamics of the much simpler global alignment algorithm. This eigenvalue equation is then explicitly solved for a simple scoring system and the resulting significance estimations are verified by a comparison to extensive numerical simulations},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {86–95},
numpages = {10},
keywords = {statistical significance, sequence alignment, Gumbel distribution},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332351,
author = {Chen, Kevin and Durand, Dannie and Farach-Colton, Martin},
title = {Notung: dating gene duplications using gene family trees},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332351},
doi = {10.1145/332306.332351},
abstract = {Large scale gene duplication is a major force driving the evolution of genetic functional innovation. Whole genome duplications are widely believed to have played an important role in the evolution of the maize, yeast and vertebrate genomes. The use of evolutionary trees to analyze the history of gene duplication and estimate duplication times provides a powerful tool for studying this process. Many studies in the molecular evolution literature have used this approach on small data sets, using analyses performed by hand. The rapid growth of genetic sequence data will soon allow similar studies on a genomic scale but such studies will be limited unless the analysis can be automated. Even existing data sets admit alternative hypotheses that would be too tedious to consider without automation.In this paper, we describe a toolbox called NOTUNG that facilitates large scale analysis, using both rooted and unrooted trees. When tested on trees analyzed in the literature, NOTUNG consistently yielded result that agree with the assessments in the original publications. Thus, NOTUNG provides a basic building block for inferring duplication dates from gene trees automatically and can also be used as an exploratory analysis tool for evaluating alternative hypotheses.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {96–106},
numpages = {11},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332352,
author = {Chen, Xin and Kwong, Sam and Li, Ming},
title = {A compression algorithm for DNA sequences and its applications in genome comparison},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332352},
doi = {10.1145/332306.332352},
abstract = {We present a lossless compression algorithm, Gen-Compress, for DNA sequences, based on searching for approximate repeats. Our algorithm achieves the best compression ratios for benchmark DNA sequences, comparing to other DNA compression programs [3, 7]. Significantly better compression results show that the approximate repeats are one of the main hidden regularities in DNA sequences.We then describe a theory of measuring the relatedness between two DNA sequences. We propose to use d(x, y) = 1 — K(x) - K(x|y)/K(xy to measure the distance of any two sequences, where K  stands for Kolmogorov complexity [5]. Here, K(x) - K(x|y) is the mutual information shared by x and y. But mutual information is not a distance, there is no triangle inequality. The distance d(x, y) is symmetric. It also satisfies the triangle inequality, and furthermore, it is universal [4].It has not escaped our notice that the distance measure we have postulated can be immediately used to construct evolutionary trees from DNA sequences, especially those that cannot be aligned, such as complete genomes. With more and more genomes sequenced, constructing trees from genomes becomes possible [1, 2, 6, 8].  Kolmogorov complexity is not computable. We use GenCompress to approximate it. We present strong experimental support for this theory, and demonstrate its applicability by correctly constructing a 16S (18S) rRNA tree, and a whole genome tree for several species of bacteria. Larger scale experiments are underway at the University of Waterloo, with very promising results.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {107},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332353,
author = {Chor, Benny and Hendy, Michael D. and Holland, Barbara R. and Penny, David},
title = {Multiple maxima of likelihood in phylogenetic trees: an analytic approach},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332353},
doi = {10.1145/332306.332353},
abstract = {Maximum likelihood (ML) is a widely used criterion for selecting optimal evolutionary trees. However, little is known on the nature of the likelihood surface for trees, especially as to the frequency of multiple optima. We initiate an analytic study for identifying sequences that generate multiple optima. We report a new approach to calculating ML directly, which we have used to find large families of sequences that have multiple optima, including sequences with a continuum of optimal points. Such datasets are best supported by different (two or more) phylogenies that vary significantly in their timings of evolutionary events Some standard biological processes can lead to data with multiple optima and consequently the field needs further investigation. Our results imply that hill climbing techniques, as currently implemented in various software packages, cannot guarantee to find the global ML point, even if it is unique.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {108–117},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332923,
author = {Davidson, Eric},
title = {Compuational analyses of developmental cis-regualtory control systems (invited presentation)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332923},
doi = {10.1145/332306.332923},
abstract = {Developmental processes are hardwired in the genomic DNA of each animal species. The DNA sequences that specify the architecture of developmental control networks are the cis-regulatory elements that individually determine the state of activity of each of the many genes required to generate a developmental event. These elements each mediate many interactions with transcription factors, which are selected with high specificity according to the target binding sites in each cis-regulatory element. Cis-regulatory elements can be thought of as analog information processing devices. This concept is illustrated by an experimental and computational analysis of a cis-regulatory system from the developmentally regulated Endo 16 gene of the sea urchin embryo. Large-scale developmental events require mobilization of batteries of downstream genes, and are instituted by signal inputs to regulatory genes encoding transcription factors. Functional linkages between genes determine which signals affect which regulatory genes, in space and time, and which gene batteries will be involved. Thus both inter cis-regulatory networks and intra cis-regulatory systems are specified by arrays of genomic target site sequences. A model of an intergenic network of this kind that controls endomesoderm specification in sea urchin embryos has been constructed on the basis of experimental information. This model consists of a set of predicted inputs and outputs to a minimal group of regulatory genes encoding endodermal and mesodermal transcription factors, and components of signaling systems. The predictions of the model are experimentally testable, and indeed some such model is a clear necessity for productive experimental analysis.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {118},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332354,
author = {Desper, Richard and Vingron, Martin},
title = {Tree fitting: an algebraic approach using profile distances},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332354},
doi = {10.1145/332306.332354},
abstract = {Distance methods play a central role in the field of phylogeny reconstruction, providing fast, efficient algorithms which yield reliable trees. The taxonomy problem is; given a set of DNA or amino acid sequences from several species, accurately reconstruct a phylogenetic tree representing their evolutionary history. Distance methods approach this problem by inferring a distance matrix of species-to-species evolutionary distances, and finding a tree which approximates the distance matrix. Our results consider the approach of using profile distances instead of leaf-to-leaf distances. We consider the vector space of tree metrics with regard to a basis generated by profile distances Given a fixed tree topology, we show how to project edge weights onto a topology based upon its set of profile distances. The projected edge weights provide topological insight, as negative edge weights will point to false edges in the topology. Although the presence of such negative edge weights is not guaranteed, we show that if the test tree is sufficiently close to the target tree in topology, negative edge weights will highlight the false edges. An algorithm is presented which uses this information to accurately reconstruct tree metrics.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {119–126},
numpages = {8},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332355,
author = {Friedman, Nir and Linial, Michal and Nachman, Iftach and Pe'er, Dana},
title = {Using Bayesian networks to analyze expression data},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332355},
doi = {10.1145/332306.332355},
abstract = {DNA hybridization arrays simultaneously measure the expression level for thousands of genes. These measurements provide a “snapshot” of transcription levels within the cell. A major challenge in computational biology is to uncover, from such measurements, gene/protein interactions and key biological features of cellular systems.In this paper, we propose a new framework for discovering interactions between genes based on multiple expression measurements This framework builds on the use of Bayesian networks for representing statistical dependencies. A Bayesian network is a graph-based model of joint multi-variate probability distributions that captures properties of conditional independence between variables. Such models are attractive for their ability to describe complex stochastic processes, and for providing clear methodologies for learning from (noisy) observations.We start by showing how Bayesian networks can describe interactions between genes. We then present an efficient algorithm capable of learning such networks and statistical method to assess our confidence in their features. Finally, we apply this method to the S. cerevisiae cell-cycle measurements of Spellman et al. [35] to uncover biological features},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {127–135},
numpages = {9},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332356,
author = {Gilbert, Walter},
title = {Invited presentation: introns and modules in ancient conserved genes (abstract only)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332356},
doi = {10.1145/332306.332356},
abstract = {We study the correlation between introns and modules, compact regions of protein structure, in genes whose products have a known 3-dimensional structre and which are homologous between bacteria and eukaryotes. Using two definitions of modules, we show that phase zero introns, those that lie between the codons, are significantly correlated with the boundaries of modules while introns that lie in phases one and two, that interrupt the codons are not so correlated. Furthermore, intron positions that are philogenetically ancient, matching between two kingdomes, are more correlated with module boundaries than are other positions. We will discuss the significance of these findings, which suggest that some of the phase zero introns are residues of the original construction of the genes while the phase one and two introns may have been added later in evolution.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {136},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332358,
author = {Gojobori, Takashi and Andrews, T. Daniel and Itoh, Takeshi},
title = {Evolutionary features of genomes as disclosed by comparative analysis of complete genome sequences (abstract only)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332358},
doi = {10.1145/332306.332358},
abstract = {Our comparisons of complete genome sequences revealed that the genome structures have been extensively shuffled among eubacteria, particularly when the orders of orthologous genes were examined. Moreover, archaebacterial and eukaryotic genome structures were found to be unstable, too, as were the cases of eubacteria. We then turned our attention to operon structures, which were expected to be well conserved during evolution because of their regulatory importance. Surprisingly enough, however, we found that even within operons, gene orders have not been conserved, with exception to only a few cases such as ribosomal operons. When we reconstructed the ancestral genome structure of eubacteria and archaebacteria, and examined the relative instability of the genome structures among eubacteria, we found that there were differences in the degree of the genome instability among the examined species. The genome instability appears to be correlated with the number of insertion sequences. Interestingly enough, the intensity of the intrastrand bias of nucleotide composition (G-C skew) was found to be affected by the genome instability, implying that accumulation of strand-specific mutations depends heavily upon the stability of a genome. These findings imply that the gene orders have not been essential for survival of microbes in long-term evolution, and that the evolutionary instability of the genome structures is an intrinsic nature common to eubacteria, archaebacteria and eukaryotes. For eukaryotic genomes, we found that a lot of gene fusion events might have happened in the early evolution of eukaryotes so as to compensate for the loss of bacterial operon structures. The evolutionary instability of the genome structures can be one of the most important factors in understanding the evolutionary processes of the genome evolution.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {137},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332359,
author = {Hallett, M. T. and Lagergren, J.},
title = {New algorithms for the duplication-loss model},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332359},
doi = {10.1145/332306.332359},
abstract = {We consider the problem of constructing a species tree given a number of gene trees. In the frameworks introduced by Goodman et al. [3], Page [10], and Guig\'{o}, Muchnik, and Smith [5] this is formulated as an optimization problem; namely, that of finding the species tree requiring the minimum number of duplications and/ or losses in order to explain the gene trees.In this paper, we introduce the WIDTH k DUPLICATION-LOSS and WIDTH k DUPLICATION problems. A gene tree has width k w.r.t. a species tree, if the species tree can be reconciled with the gene tree using at most k simultaneously active copies of the gene along its branches. We explain w.r.t. to the underlying biological model, why this width is typically very small in comparison to the total number of duplications and losses. We show polynomial time algorithms for finding optimal species trees having bounded width w.r.t. at least one of the input gene trees. Furthermore, we present the first algorithm for input gene trees that are unrooted. Lastly, we apply our algorithms to a dataset from [5] and show a species tree requiring significantly fewer duplications and fewer duplications/losses than the trees given in the original paper.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {138–146},
numpages = {9},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332360,
author = {Hart, Reece and Royyuru, Ajay K. and Stolovitzky, Gustavo and Califano, Andrea},
title = {Systematic and automated discovery of patterns in PROSITE families},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332360},
doi = {10.1145/332306.332360},
abstract = {PROSITE is a method for protein classification which relies on a database of biologically significant sites and patterns in protein sequences. Most patterns in PROSITE have been gathered by a a labor intensive combination of experimental characterization of functional residues and sequence alignment. In this paper we present a new and efficient supervised learning procedure, based on the Splash deterministic pattern discovery algorithm and on a framework to assess the statistical significance of patterns. We demonstrate its application to the fully automatic discovery of patterns in 974 PROSITE families. For these families, Splash generates patterns with better specificity and/or sensitivity in 28\%, identical statistics in 48\%, and worse statistics in 15\% of the cases; for the remaining families, patterns exhibited mixed behavior. Second, we have characterized the amount of overlap, on the sequences, between newly discovered patterns and those in PROSITE. In about 75\% of the cases, Splash patterns identify sequence sites that overlap more than 50\% with those reported in PROSITE. Of the 272 patterns which perform strictly better than the corresponding PROSITE pattern, 178 show more than 70\% overlap with the PROSITE pattern. Third, our results suggest that the statistical significance of discovered patterns correlates well with their biological significance. Finally, we use the trypsin subfamily of serine proteases to illustrate the use of this method to exhaustively discover all motifs in a family that are statistically and biologically significant. The complete analysis is sufficiently rapid, taking less than a day for all PROSITE families, to enable the use this methodology for routine curation of existing motif and profile databases.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {147–154},
numpages = {8},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332361,
author = {Heber, Steffan and Stoye, Jens and Hoheisel, J\"{o}rg and Vingron, Martin},
title = {Contig selection in physical mapping},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332361},
doi = {10.1145/332306.332361},
abstract = {In physical mapping one orders a set of genetic landmarks or a library of cloned fragments of DNA according to their position in the genome. This is a preparatory step for efficient sequencing.Our approach to physical mapping divides the problem into smaller and easier subproblems by partitioning the probe set into independent parts (contigs). The focus is on the selection of probe sets which can be grouped together into contigs. We introduce a new distance function between probes, the averaged rank distance (ARD). The ARD measures the reliability of certain probe configurations in physical maps which are generated by bootstrap resampling of the raw data. This mimics an independent experiment repetition in silico. The ARD measures the distances of probes within a contig and smoothes the distances of probes in different contigs. It shows distinct jumps at contig borders. This makes it appropriate for contig selection by clustering. We designed a physical mapping algorithm that makes use of these observations and seems to be particularly well suited to the delineation of reliable contigs.We evaluated our method on data sets from two physical mapping projects. In comparison to a physical map of Pasteurella haemolytica that was computed using simulated annealing, the newly computed map is considerably cleaner. On data from Xylella fastidiosa the contigs produced by the new method could be compared to a map produced by a group of experts and the two maps largely agree in the definition of the contigs. The results of our method have already proven helpful for the design of experiments aiming at further improving the quality of a map.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {155–164},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332362,
author = {Hennig, S. and Herwig, R. and Clark, M. and Aanstad, P. and Musa, A. and O'Brien, J. and Bull, C. and Radelof, U. and Panopoulou, G. and Poustka, A. J. and Lehrach, H.},
title = {A data-analysis pipeline for large-scale gene expression analysis},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332362},
doi = {10.1145/332306.332362},
abstract = {In this article we describe a method for characterization of large cDNA clone libraries based on oligonucleotide fingerprints (OFPs). The main advantage of this technique lies in that, without sequencing, each clone is tagged in an almost unique way, which has a couple of interesting applications, e.g. clustering of clones that belong to the same gene or gene family followed by sequencing of representative clones for each cluster. Moreover, small clusters are likely to represent rarely expressed genes, which are difficult to find by common approaches. We will demonstrate that in the EST projects carried out in our lab the global redundancy is very low compared to similar projects described in the literature, and simultaneously the number of unknown (novel) genes detected using this method is very high. In addition OFPs can be used directly for data base mining, since the sequences of the oligos matching a specific clone is known Recent results are presented, which underline the potential of our method in finding novel genes or genes homologous to known data. We will also address future applications in gene expression profiling, and give an outline of the various bioinformatics tools, which have been developed so far and which are used for automated data processing and analysis.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {165–173},
numpages = {9},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332363,
author = {Hood, Leroy},
title = {Computing life and global technologies (abstract only)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332363},
doi = {10.1145/332306.332363},
abstract = {The view “Biology is an informational science” is now widely accepted—certainly catalyzed in part by the success of the Human Genome Project. There are three levels of biological information: 1-dimensional information of DNA, the 3-dimensional information of proteins, and the 4-dimensional (time variant) information of biological systems and networks. The key to deciphering biological information at each of these levels are the global technologies which analyze many genes, DNAs or proteins at one time. I will discuss several new and pioneering global technologies for genomics and proteomics. Information at each of these levels poses striking computational challenges, which will be discussed. The importance of the need for intimate interactions between biologists, computer scientists and mathematicians will also be discussed, as well as a new approach for teaching biology that may be effective for cross-disciplinary communication.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {174},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332365,
author = {Kaessmann, Henrik and Ebersberger, Ingo and Wiebe, Victor and Erlandsson, Rikard and Wilson, Jim F. and Schwarz, Carsten and Winkler, Michaela and P\"{a}\"{a}bo, Svante},
title = {DNA sequence variation among humans and apes (abstract only)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332365},
doi = {10.1145/332306.332365},
abstract = {In order to shed light on the rate and mode of evolution of DNA sequence evolution in the germ line of humans and chimpanzees, we have sequenced 136 kb around the human ZFY gene as well as a total of 180 kb of genomic DNA surrounding the ZFX and ZFY genes on the chimpanzee X and Y chromosome, respectively. The comparison of the orthologous sequences on the human and chimpanzee sex chromosomes show that whereas the ZFX region display 0.8\% substitutional differences between the two species, the ZFY region display 1.5\% differences. By contrast, insertions and deletions show no difference between the two regions. Interestingly, transversions show a much more drastic preponderance in the male germ line than transitions, and the insertion of retroviral-like elements seem to occur more frequently in the male than in the female germ line.While data on nucleotide sequence variation in the human nuclear genome have begun to accumulate through comparative sequencing projects at several diseases-associated genes, little is known about genomic variation in non-coding parts of the human genome and practically nothing about the variation in chimpanzee genome. In order to begin to gauge the extent and pattern of point substitutional variation in the non-transcribed parts of the human genome, we have sequenced 10 kb of non-coding DNA in a region of low recombination at Xq13.3 from 70 humans representing all major language groups of the world. In addition, the same sequence has been determined from 30 chimpanzees, representing all major subspecies, as well as bonobos. Comparison to humans reveals an almost four-fold higher diversity and a three-fold greater age of the most recent common ancestor of the chimpanzee sequences. Phylogenetic analyses show the sequences from the different chimpanzee subspecies to be intermixed and the distance between some chimpanzee sequences to be greater than the distance between them and the bonobo sequences. These data, as well as preliminary work in the other great apes, indicate that the human genome is unique in carrying extremely little nucleotide diversity.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {175},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332366,
author = {Kanehisa, Minoru},
title = {Sequence comparison to graph comparison—a new generation of algorithms for network analysis of interacting molecules (abstract only)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332366},
doi = {10.1145/332306.332366},
abstract = {The sequence comparison has been the most fundamental method for understanding molecular functions encoded in the sequence data of proteins and nucleic acids. In general, however, the biological function results from an ordered network of interacting molecules in the cell; it cannot be attributed to just a single protein or a single gene. With the availability of complete genome sequences, it is now necessary to analyze multiple proteins or multiple genes at a time in order to understand higher level cellular functions, such as metabolism, signal transduction, cell cycle, apoptosis, and development.We have been computerizing current knowledge on cellular processes in KEGG (http://www.genome.ad.jp/kegg/) in terms of the network of interacting molecules. For simplicity of correlating with the genomic information, we abstract the interactions at the level of gene products- mostly proteins but including RNAs. Thus, the `generalized' protein-protein interactions include direct interactions, such as binding and phosphorylation in the signal transduction pathway, enzyme-enzyme relations in two successive reaction steps in the metabolic pathway, and the relations of transcription factors and transcribed gene products in the gene regulatory network. The latter two type of interactions are termed `indirect' protein-protein interactions.The generalized protein-protein interaction network is represented as a graph with gene products as nodes and interactions as edges. The genome is also represented as a graph where genes are nodes and they are considered to be linked one-dimensionally. Then, the functional prediction (reconstruction) from the genome is a process of mapping gene nodes in the genome to gene product nodes in the interaction network, which is a conversion of one graph to another graph. To help this mapping or conversion, additional graphs can also be considered, such clusters of coregulated genes by gene expression profile experiments or groups of orthologous and paralogous genes by sequence similarity searches. I will discuss graph comparison and path computation algorithms and their practical applications in functional reconstruction problems.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {176},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332536,
author = {Kann, Maricel and Goldstein, Richard A.},
title = {Optimizing for success: a new score function for distantly related protein sequence comparison},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332536},
doi = {10.1145/332306.332536},
abstract = {The exponential growth of the sequence data produced by the genome projects motivates the development of better ways of inferring structural and functional information about those newly sequenced proteins. Looking for homologies between these probe protein sequences and other protein sequences in the database has proved to be one of the most useful current techniques. This procedure, known as sequence comparison, relies on the use of an appropriate score function that discriminates homologs from non-homologs. Current score functions have difficulty identifying distantly-related homologs with low sequence similarity. As a result, there is an increased demand for a new score function that yields statistically-significant higher scores for all the pairs of homologous protein sequences including such distantly-related homologs. We present a new method for generating a score function by optimizing it for successful discrimination between homologous and unrelated proteins. The new score function (OPTIMA) out-performs other commonly used substitution matrices for the detection of distantly related protein sequences.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {177–182},
numpages = {6},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332540,
author = {Krececioglu, John and Shete, Sanjay and Arnold, Jonathan},
title = {Reconstructing distances in physical maps of chromosomes with nonoverlapping probes},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332540},
doi = {10.1145/332306.332540},
abstract = {We present a new method for reconstructing the distances between probes in physical maps of chromosomes constructed by hybridizing pairs of clones under the so-called sampling-without-replacement protocol. In this protocol, which is simple, inexpensive, and has been used to successfully map several organisms, equal-length clones are hybridized against a clone-subset called the probes. The probes are chosen by a sequential process that is designed to generate a pairwise-nonoverlapping subset of the clones. We derive a likelihood function on probe spacings and orders for this protocol under a natural model of hybridization error, and describe how to reconstruct the most likely spacing for a given order under this objective using continuous optimization. The approach is tested on simulated data and real data from chromosome VI of Aspergillus nidulans. On simulated data we recover the true order and close to the true spacing; on the real data, for which the true order and spacing is unknown, we recover a probe order differing significantly from the published one. To our knowledge this is the first practical approach for computing a globally-optimal maximum-likelihood reconstruction of interprobe distances from clone-probe hybridization data.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {183–192},
numpages = {10},
keywords = {computational biology, convex optimization, maximum likelihood, physical mapping of chromosomes, sampling without replacement protocol},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332544,
author = {Liwo, Adam and Pillardy, Jaroslaw and Czaplewski, Cezary and Lee, Jooyoung and Ripoll, Daniel R. and Groth, Malgorzata and Rodziewicz-Motowidlo, Sylwia and Kamierkiewicz, Rajmund and Wawak, Ryszard J. and Oldziej, Stanislaw and Scheraga, Harold A.},
title = {UNRES: a united-residue force field for energy-based prediction of protein structure—orgin and significance of multibody terms},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332544},
doi = {10.1145/332306.332544},
abstract = {United-residue models of polypeptide chains [3, 5, 19-22, 24, 31, 33] have long been of interest, because they enable one to carry out global conformational searches of proteins in real time, which in turn can facilitate ab initio protein structure predictions based solely on Anfinsen's thermodynamic hypothesis [1], according to which the native structure of a protein is a global minimum of its potential energy surface [32]. In the last few years, we developed a united-residue force field [20-22, 24], hereafter referred to as UNRES, in which a polypeptide chain is represented by a sequence of α-carbon (Cα) atoms linked by virtual bonds with attached united side chains (SC) and united peptide groups (p) located in the middle between the consecutive α-carbons (Figure 1). Only the united peptide groups and united side chains serve as interaction sites, the α-carbons serving to define the geometry.All the virtual bond lengths (i.e. Cα-Cα and Cα-SC) are fixed; the Cα-Cα distance is taken as 3.8 \r{A} which corresponds to trans peptide groups, while the side-chain angles (αSC and ΒSC), as well the virtual-bond angles (θ and γ) can vary. The energy of the virtual-bond chain is expressed by eq. (1). U = @@@@ Uscisci + @@@@ UsciPj + wel @@@@ UPiPj + wtor @@@@ Utor(γi) + wloc @@@@ (Ub(θi) + Urat(αsci, Βsci)] + wcorrUcorr (1)In contrast to all-atom force fields, the multibody terms are not just a small addition; the multi-body terms are an essential ingredient of coarse-grain united-residue force fields. This is because coarse-grain potentials are mean-field potentials, corresponding to the restricted free energy, F(X), calculated for given configurations of the “coarse-grain” interaction sites (p and SC in the case of the UNRES force field; Figure 1) and to averaging over the remaining, “less important” degrees of freedom, as expressed by eq. (2) [20]. F(X) = -RTln{1/VY @@@@ exp[-E(X;Y)/kBT]dVY} with VY = @@@@ dVY. (2) where E(Xi Y) is the original energy function, X denotes the vector of the degrees of freedom of the “coarse-grain” system (the virtual bond angles θ, the virtual-bond dihedral angles γ, and the polar angles ΒSC and γSC in UNRES), Y denotes the vector of the degrees of freedom over which the average is computed (e.g., the positions and orientations of solvent molecules, the side-chain dihedral angles Χ, etc.), R is the gas constant, T is the absolute temperature, ΩY is the region of the Y subspace of variables over which the integration is carried out and VY is the volume of this region.Expanding F(X) of eq. (2) in the cumulant series in Β = 1/RT, we obtain [20]: F(X) ≅ F(Β,X) = U1 - 1/2(U21)Β + 1/6(U3 - 3U1U2 + 2U31)Β2 - 1/24(U4 - 3U22 - 4U1U3 + 12U21U2 - 6U41)Β3 + … = @@@@ (-1)k-1/k!Ck(X)Βk-1 (3) where Ck is the k-th order cumulant and U1, U2, … Un are consecutive energy moments: Uk = 1/VY@@@@E(X;Y)kdVY (4)Even if the original energy function E(Xi Y) contains at most pairwise terms, the restricted free energy F(X) will in general contain higher-order terms that arise from the presence of higher energy moments in the cumulant expansion [eq. (3)]. The early version of UNRES [22, 24] did not contain multibody terms and was therefore good only for inverse folding (i.e., it could recognize a native fold corresponding to a given amino-acid sequence in the data base of decoys taken from the PDB), but was not capable of de novo folding of a protein [22, 24]. The capability of de novo folding was achieved only after introducing multibody or correlation terms in the backbone electrostatic interactions [20, 23]. Similar conclusions about the role of backbone hydrogen bonding and other multi-body terms have also been drawn by other workers [5, 10, 11].The side-chain (USCSC) and the components of the local-interaction potential (Utor, Ub, and Urot) were parameterized based on distribution and correlation functions determined [22, 24] from a set of 195 high-resolution non-homologous structures from the Protein Data Bank (PDB) [2]. The peptide-group interaction potential Upipi and the correlation terms pertaining to backbone hydrogen bonding (Ucorr) were parameterized by averaging the all-atom ECEPP/2 [27,28] potential. Finally, the relative weights of the energy terms were determined so as to maximize the energy gap between the native structure and the average energy of the non-native structures [24]; this was accomplished by the minimization of the so-called Z-score function [6-9].The version of the UNRES force field described above with the Conformational Space Annealing (CSA) global-optimization procedure [16-18] was first tested on two simple helical proteins: the 10-58 fragment of the B-domain of staphylococcal protein A (a three-helix-bundle topology) and apo-calbindin D9K (a 75-residue protein with the topology of a four-helix bundle with an EF-hand motif) [15]. In both cases, the native structure and its mirror image were located; the native structure was lower in energy for protein A, and higher for apo-calbindin. A full-blown blind-prediction test was performed within the CASP3 experiment. We submitted predictions for seven targets, one of which, for the periplasmic protein HDEA from E. coli, turned out to be the most accurate one among all the models submitted [30], including homology modeling and threading (Figure 2). We also achieved very good results for DNA b helicase, a 116-residue protein. These two proteins were assessed as particularly difficult targets [30], because of their rare folds. Our predictions of most of the other targets were also fairly accurate [13, 14, 21, 30]. However, the version of the UNRES force field that includes only the multi-body terms pertaining to hydrogen bonding produces too-distorted Β-structure.In our present work, we introduced two new types of multibody terms: Umulttor and Uel,loc thet arise from the coupling between local interactions involving more than two consecutive peptide units and local and backbone electrostatic interactions, respectively. These terms comprise the third — sixth order terms in the cumulant expansion for the restricted free energy [eq. (3)]. These new terms should extend the performance of our procedure to proteins that contain Β-structure. By local-interaction energy (Eloc), we denote the conformational energy of an isolated peptide unit. Eloc can be modeled by the energy surface of an N-acetyl-N'-methylamide derivative of the amino acid residue under study [35]. It is usually expressed as a function of the dihedral angles φ and ψ however, for the purpose of implementing it in eqs. (2) and (3), we express it as a function of the dihedral angles of rotation λ1 and λ2 about the Cα-Cα bonds forming the peptide unit [29] (Figure 3), which provides a clear separation of the degrees of freedom into the “coarse” or “important” ones [X of eq. (2)] and “fine” or “less important” ones [Y of eq. (2)], the “less important” ones being the dihedral angles λ [25, 26]. The dihedral angles φ and ψ describe both the “coarse” and “fine” shape of the polypeptide backbone and cannot therefore be implemented directly in the calculation of the restricted free energy.The lowest-energy conformations (i.e., region C) [35] of terminally-blocked L-amino acid residues (the smallest peptide units) lie exactly in the region of the (φ, ψ)-dihedral angle space characteristic of Β-structure. Therefore, the mixed local and electrostatic energy moments in the cumulant expansion of the restricted free energy of the polypeptide chain [eq. (3)] contribute to the stabilization of Β-structures.The contributions to consecutive energy moments [needed to compute the cumulant expansion for F(X) in eq. (3)] that include the products of the local and electrostatic energies have the following general form: Uk;el,loc = 1/(2π)Nk @@@@ … @@@@ EjlocEk-jeldλi1dλi2 … λiNk, j = 1, 2, …, k-1; k= 2, 3, … (5) where λi1, λi2 … λiNh indicate the dihedral angles λ involved in integration (their number, Nk1 will vary depending on the contribution to the energy moment). Likewise, the contributions needed to determine multiple-torsional terms (Umulttor) are expressed by eq. (6). Umultk;tor = 1/(2π)Nk @@@@ … @@@@ Eklocdλi1dλi2 … λiNk, k= 2, 3, … (6) To a very good approximation, Eloc(λ1, λ2) can be expressed as a second-order Fourier series in λ1 and λ2. In our dipole model of the peptide group [25], the energy of electrostatic interaction between peptide groups is a second-order Fourier series in the angles λ (this follows directly from the energetics of the dipole-dipole interactions [25]). Therefore, all energy moments involving the local and/or the electrostatic energy can be calculated analytically. In our earlier work [20], we developed an algorithm for calculating the moments of the electrostatic-interaction energy; this algorithm was used to derive the hydrogen-bonding multibody terms in UNRES. We have now generalized this algorithm to compute the energy moments involving both electrostatic and local interactions, and derived the terms in the cumulant expansion for F(X) [eq. (3)] up to the sixth order. Instead of writing the complicated formulas for the component terms here, we present them as graphs in Figures 4, 5a and 5b. Figure 4 includes the terms already present in the original version of UNRES, while Figures 5a and 5b show the new terms.In Figure 4, the upper left graph represents the averaging of the square of the energy of the electrostatic interactions between the peptide groups; it corresponds to the contribution to Upp of eq. (1) coming from a pair of interacting peptide groups. The upper right graph corresponds to the averaging of the products of local-interaction energy of two consecutive peptide units. As a result of this, the average becomes dependent on the virtual dihedral angle γ centered at the Cα-Cα virtual bond connecting the two units. This term formally corresponds to Utor of eq. (1). Both of the graphs described above come from second moments of the energy of the all-atom chain. The middle and the bottom graphs represent the dominant three- and four-body contributions to the restricted free energy. They were derived in our earlier work [20] as the components of the third and the fourth-order term in the cumulant expansion of the backbone electrostatic energy. However, they also include the averaging of the electrostatic energy between neighboring peptide groups, which is a part of the local interaction energy of the peptide unit to which these peptide group belong. Therefore, these terms should be considered as parts of Uel,loc.The third-order components of Uel,loc presented in Figure 5a describe the correlation between the energy of the electrostatic interaction between two non-contiguous peptide groups and the energy of local interaction of the neighboring peptide units.As shown, these terms are dependent not only on the relative orientation of the two peptide groups, but also on the virtual-bond dihedral angles γ1 and γ2 centered on the corresponding Cα-Cα virtual-bond axes. In other words, a given orientation of two peptide groups invokes a certain local fold of the respective portion of the polypeptide chain, or, long-range interactions have the capacity of propagating an ordered local structure. Figure 6 shows that a parallel or antiparallel orientation of two interacting peptide groups, as in Β-sheets, favors extended virtual-bond dihedral angles and, thus propagates extended configurations of the polypeptide chain as in Β-strands (note the minimum at γ1 = γ2 = ±180°). The fifth- and sixth-order components displayed in Figure 5b should also be important, because they propagate the local fold of the chain, if two pairs of neighboring peptide groups are in contact.The double torsional terms (Umulttor; represented as the middle graph in the bottom of Figure 5a) should also be important with regard to the formation of ordered structures. Their importance has already been pointed out by other workers [4]. From our preliminary analysis, it appears that these double torsional terms contribute to the stabilization of left-handed extended strands [which, in turn, lead to (the observed) right-handed Β-sheets]. The other two third- and fourth-order terms shown in the bottom part of Figure 5a involve local and electrostatic interaction correlations within three and four adjacent peptide units, respectively; they can be important for the correct description of the geometry of Β- or γ-turns and of the geometry of α-helices.To test the ability of UNRES augmented with the new correlation terms to reproduce the structure of Β-sheets, we used the sequence of a 20-residue polypeptide betanova, which was recently designed as a minimum Β-sheet model [12]. This peptide forms a stable three-stranded Β-sheet in solution, as revealed by NMR spectroscopy [12]. The first calculation was carried out without including the new features of the force field (i.e., the only multibody terms included are those shown in Figure 4), while the second one was carried out with inclusion of the third-, fourth- and fifth-order correlation terms that are depicted in Figure 5; these term pertain to the coupling between local and electrostatic interactions. In both cases the CSA method [16-18] was used to find the global minimum. As shown, lack of sufficient terms responsible for the coupling between the local and backbone hydrogen-bonding interactions leads effectively to a coil structure (Figure 7a). Including the multibody terms introduced in this work leads to correct topology of betanova with correct positions of both turns and correct contacts between the side chains [12]. It should be noted that this result was obtained even without systematic calibration of the weights of the new correlation contributions to energy. At present, we are determining the weights of the new correlation terms in a systematic way by means of Z-score optimization.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {193–200},
numpages = {8},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332551,
author = {Lyngs\o{}, Rune B. and Pedersen, Christian N. S.},
title = {Pseudoknots in RNA secondary structures},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332551},
doi = {10.1145/332306.332551},
abstract = {RNA molecules are sequences of nucleotides that serve as more than mere intermediaries between DNA and proteins, e.g. as catalytic molecules. Computational prediction of RNA secondary structure is among the few structure prediction problems that can be solved satisfactory in polynomial time. Most work has been done to predict structures that do not contain pseudoknots. Allowing pseudoknots introduce modelling and computational problems. In this paper we consider the problem of predicting RNA secondary structure when certain types of pseudoknots are allowed. We first present an algorithm that in time Ο(n5) and space Ο(n3) predicts the secondary structure of an RNA sequence of length n in a model that allows certain kinds of pseudoknots. We then prove that the general problem of predicting RNA secondary structure containing pseudoknots is NP-complete for a large class of reasonable models of pseudoknots.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {201–209},
numpages = {9},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332553,
author = {Marsan, Laurent and Sagot, Marie-France},
title = {Extracting structured motifs using a suffix tree—algorithms and application to promoter consensus identification},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332553},
doi = {10.1145/332306.332553},
abstract = {This paper introduces two exact algorithms for extracting conserved structured motifs from a set of DNA sequences. Structured motifs are composed of p ⪈ 2 parts separated by constrained spacers These algorithms use a suffix tree for fulfilling this task. They are efficient enough to be able to extract site consensus, such as promoter sequences, from a whole collection of non coding sequences extracted from a genome. In particular, their time complexity scales linearly with N2n where n is the average length of the sequences and N their number. An application with interesting results to the identification of promoter consensus sequences in bacterial genomes is shown.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {210–219},
numpages = {10},
keywords = {suffix tree, structured motif, promoter, motif extraction, model, consensus},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332555,
author = {Martin, Yvonne C. and Bures, Mark G.},
title = {Molecular diversity (abstract only): strategies and concerns},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332555},
doi = {10.1145/332306.332555},
abstract = {Automation has produced the opportunity to test hundreds of thousands of compounds in a biological test. The challenge of the computational chemist is to select, from the 10180 possible drug-like molecules, those that are most attractive for screening, those that could form the basis of a medicinal chemistry program. Early work focused on selecting diverse compounds, leading to the question of how similar compounds must be in order for them to have similar biological activity. The issue, of course, is how to quantitate the similarity—which molecular descriptors and which similarity calculation provide the best result. More recent work has emphasized the consideration of physical properties to eliminate compounds, with the challenge of finding accurate and comprehensive methods to calculate these properties.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {220},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332557,
author = {Nakamura, Yusuke},
title = {Human genome analysis and medicine in the 21st century (abstract only)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332557},
doi = {10.1145/332306.332557},
abstract = {The human genome project is now considered to be the most important project in biological and medical research. The discovery of entire human genes that are estimated to be 70,000-150,000 in our genome, through this project must revolutionize biological medicine including molecular diagnosis of various diseases and development or novel treatment. DNA sequences of an entire human genome consisting of 3X109 nucleotides will be completely determined by 2003, and 90\% of our genes will be identified by 2001 although it will take 10-20 years to obtain the information of their biological functions. Such information will accelerate discovery of genes susceptible to or causing various diseases and should contribute to screening of novel drugs that target these disease-gene products.In this regard, analysis of expression profiles and SNPs (single nucleotide polymorphisms) using microarray or DNA-chip is quite important. Microarray or DNA chip technology has made it possible to examine expression levels of thousands of genes and genotype a huge number of SNPs by a single experiment. We have been applying microarray analysis for screening of genes involving in colorectal, hepatocellular, and ovarian carcinogenesis as well as those related to responsiveness to anti-cancer drugs and those involving in various signal trunsduction pathways of medical importance. We have so far established a system to analyze 15,000 genes and are accumulating the expression profile data of various types of cancer cells. For example, we analyzed cancer tissues of 13 esophageal cancer patients who were treated by the same chemotherapy after their operation. Although all of them had an advanced cancer and could not have curative operation, four patients achieved a very long survival of 43-103 months, indicating that the chemotherapy was very efficient to these four patients. In contrast, four patients had very short survival of 4-12 months. A comparison of expression profiles of the patients with very short or very long survivals has disclosed that the expression levels of nearly 50 genes may be associated with responsiveness of the chemotherapy. This result implies that examination of expression levels of a set of genes may be a good predictor for a certain anti-cancer treatment. At present, a large number of cancer patients are treated with anti-cancer drugs without any knowing whether the drugs are effective to their cancer cells and a significant proportion of them suffered from side-effects without no effect. Hence, our approach must contribute to predict the effect before the patients start to have treatment with anti-cancer drugs.Secondary, we have also been examining genes which are up-regulated or down-regulated in a certain biological condition by means of microarray coupled with laser-captured microdissection (LCM). A comparison of expression levels of normal mucosal cells, adenoma cells, and cancer cells from the same patients with colorectal tumor, we identified dozens of genes whose expression levels were significantly increased or decreased in tumor cells. The results clearly indicated that the microarray analysis is a very powerful tool to examine genes involving in carcinogenesis.In addition to the expression profile analysis, the recent world-wide effort of the SNP (single nucleotide polymorphism) project that aims to discover 300,000 or more genetic variations in our genome will generate very valuable resources. We undertook a systematic survey of genomic DNA for SNPs located not only in coding sequences but also in non-coding regions (e.g introns and 5' flanking regions) of genes of medical interest. Using DNA samples from Japanese patients with rheumatoid arthritis (RA) or myocardial infarction (MI) as templates, we surveyed 82 genes that represent candidates for RA or MI, screening a total of 224 kb of DNA (107 kb of coding sequences and 117 kb of non-coding DNA). Within this 224-kb genomic sequences we identified 329 SNPs (1 per 680 bases on average), 50 insertions or deletions. Fifty-two percent of the coding SNPs were non-synonymous substitutions, and non-conservative amino acid changes were observed in a quarter of those. Allelic frequencies of some of the polymorphisms were significantly different from those reported in European populations. For example, the Q506R substitution in the coagulation factor V gene, the so-called “Leiden mutation”, has a reported frequency of 2.3\% in Europeans, but we detected the Leiden mutation in none of the Japanese genomes we investigated. The allelic frequencies of the 33 — A&gt;G SNP in the thrombomodulin gene were also very different; this allele occurred at 12\% frequency in the Japanese patients we examined, although it had been detected in none of 82 Caucasians reported previously. These data support the hypothesis that some SNPs are specific to particular ethnic groups.In the meeting, I introduce the recent progress and future direction of human genome analysis and its impact on the medical science.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {221–222},
numpages = {2},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332558,
author = {Ohkubo, Y. Zenmei and Crippen, Gordon M.},
title = {Determining contact energy function for continuous state models of globular protein conformations},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332558},
doi = {10.1145/332306.332558},
abstract = {One of the approaches to protein structure prediction is to obtain energy functions which can recognize the native conformation of a given sequence among a zoo of conformations. The discriminations can be done by assigning the lowest energy to the native conformation, with the guarantee that the native is in the zoo. Well-adjusted functions, then, can be used in the search for other (near-) natives. Here the aim is the discrimination at relatively high resolution (RMSD difference between the native and the closest nonnative is around 1 \r{A}) by pairwise energy potentials. The results show that the potential can be trained to discriminate between the native conformation of one protein as the (near-) global minimum, and other nonnatives, including energy-minimized ones (or local minima). This potential function is able to identify the native conformation of another protein, too.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {223–230},
numpages = {8},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332560,
author = {Pevzner, Pavel A. and Dan\v{c}\'{\i}k, Vlado and Tang, Chris L.},
title = {Mutation-tolerant protein identification by mass-spectrometry},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332560},
doi = {10.1145/332306.332560},
abstract = {Database search in tandem mass spectrometry is a powerful tool for protein identification. High-throughput spectral acquisition raises the problem of dealing with genetic variation and peptide modifications within a population of related proteins. A method that cross-correlates and clusters related spectra in large collections of uncharacterized spectra (i.e from normal and diseased individuals) would be extremely valuable in functional proteomics. This problem is far from being simple since very similar peptides may have very different spectra. We introduce a new notion of spectral similarity that allows one to identify related spectra even if the corresponding peptides have multiple modifications/mutations. Based on this notion we developed a new algorithm for mutation-tolerant database search as well as a method for cross-correlating related uncharacterized spectra. The paper describes this new approach and its applications in functional proteomics.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {231–236},
numpages = {6},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332561,
author = {Portugaly, Elon and Linial, Michal},
title = {Probabilities for having a new fold on the basis of a map of all protein sequences},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332561},
doi = {10.1145/332306.332561},
abstract = {It is a major problem in the study of protein structure to predict which proteins have new, currently unknown structural folds. In an attempt to address this problem we studied the location of all proteins with solved structures within the map of all known protein sequences provided by ProtoMap. The mutual distances in this map among solved structures are used to derive a probabilistic model from which we infer an estimate for the probability of an unsolved protein to have a new fold. The probabilities were based on data from SCOP release 1.37. The results were evaluated against the more recent SCOP pre-release 1.41. Our predicted probabilities for unsolved proteins to have a new fold are very well correlated with the proportion of new folds among recently released structures. Thus, information about the structure of proteins can be inferred from a global relational view of protein sequences. Finally, the same procedure was applied to estimate probabilities on the basis of SCOP 1.41. A list of the highest scoring proteins is provided: These are about 80 non-membranous proteins that belong to clusters with more than 5 proteins and achieve the highest probability to have a new fold. A rational selection for 3D determination of those targets is expected to accelerate the pace of new fold discovery.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {237–244},
numpages = {8},
keywords = {structure prediction, structural genomics, statistical mode, global protein organization, clustering},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332562,
author = {Preparata, Franco P. and Upfal, Eli},
title = {Sequencing-by-hybridization at the information-theory bound: an optimal algorithm},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332562},
doi = {10.1145/332306.332562},
abstract = {In a recent paper [PFU99) we have introduced a novel probing scheme for DNA sequencing by hybridization (SBH). The new gapped-probe scheme combines natural and universal bases in a well defined periodic pattern. It was shown in [PFU99] that the performance of the gapped-probe scheme (in terms of the length of a sequence that can be uniquely reconstructed using a given library size of probes) is significantly better than the standard scheme based on oligomer probes.In this paper we present and analyze a new, more powerful, sequencing algorithm for the gapped-probe scheme. We prove that the new algorithm exploits the full potential of the SBH technology with high-confidence performance, that comes within a small constant factor (about 2) of the information-theory bound. Moreover, this performance is achieved while maintaining running time linear in the target sequence length.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {245–253},
numpages = {9},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332563,
author = {Sankoff, David and Bryant, David and Deneault, M\'{e}lanie and Lang, B. Franz and Burger, Gertraud},
title = {Early eukaryote evolution based on mitochondrial gene order breakpoints},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332563},
doi = {10.1145/332306.332563},
abstract = {We present a general heuristic for the median problem for induced breakpoints on genomes with unequal gene content and incorporate this into a routine for estimating optimal gene orders for the ancestral genomes in a fixed phylogeny. The routine is applied to a phylogenetic study of an up-to-date set of completely sequenced protist mitochondrial genomes, confirming some of the recent sequence-based groupings which have been proposed and, conversely, confirming the usefulness of the breakpoint method as a phylogenetic tool even for small genomes.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {254–262},
numpages = {9},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332564,
author = {Slonim, Donna K. and Tamayo, Pablo and Mesirov, Jill P. and Golub, Todd R. and Lander, Eric S.},
title = {Class prediction and discovery using gene expression data},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332564},
doi = {10.1145/332306.332564},
abstract = {Classification of patient samples is a crucial aspect of cancer diagnosis and treatment. We present a method for classifying samples by computational analysis of gene expression data. We consider the classification problem in two parts: class discovery and class prediction. Class discovery refers to the process of dividing samples into reproducible classes that have similar behavior or properties, while class prediction places new samples into already known classes. We describe a method for performing class prediction and illustrate its strength by correctly classifying bone marrow and blood samples from acute leukemia patients. We also describe how to use our predictor to validate newly discovered classes, and we demonstrate how this technique could have discovered the key distinctions among leukemias if they were not already known. This proof-of-concept experiment paves the way for a wealth of future work on the molecular classification and understanding of disease.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {263–272},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332565,
author = {Sorenson, Jon M. and Head-Gordon, Teresa},
title = {Matching simulation and experiment (extended abstract): a new simplified model for simulating protein folding},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332565},
doi = {10.1145/332306.332565},
abstract = {Simulations of simplified protein folding models have provided much insight into solving the protein folding problem. We propose here a new off-lattice bead model, capable of simulating several different fold classes of small proteins. We present the sequence for an α/β protein resembling the IgG-binding proteins L and G. The thermodynamics of the folding process for this model are characterized using the multiple multi-histogram method combined with constant-temperature Langevin simulations. The folding is shown to be highly cooperative, with chain collapse nearly accompanying folding. Two parallel folding pathways are shown to exist on the folding free energy landscape. One pathway contains an intermediate—similar to experiments on protein G, and one pathway contains no intermediates—similar to experiments on protein L. The folding kinetics are characterized by tabulating mean-first passage times, and we show that the onset of glasslike kinetics occurs at much lower temperatures than the folding temperature. This model is expected to be useful in many future contexts; investigating questions of the role of local versus non-local interactions in various fold classes, addressing the effect of sequence mutations affecting secondary structure propensities, and providing a computationally feasible model for studying the role of solvation forces in protein folding.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {273–282},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332566,
author = {Teichmann, S. A. and Chothia, C. and Church, G. M. and Park, J.},
title = {PDB_ISL: an intermediate sequence library for protein structure assignment},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332566},
doi = {10.1145/332306.332566},
abstract = {For large scale structural assignment to sequences, as in computational structural genomics, a fast yet sensitive homology search procedure is essential. A new approach using intermediate sequences was tested as a shortcut to iterative multiple sequence search methods such as PSI-BLAST and hidden Markov models. A library containing potential intermediate sequences for proteins of known structure (PDB_ISL) was constructed. The sequences in the library were collected from a large sequence database using the sequences of the domains of proteins of known structure as the query sequences and the program PSI-BLAST. Sequences of proteins of unknown structure can be matched to distantly related proteins of known structure by using any pairwise sequence comparison methods to find homologues in PDB_ISL. Searches of PDB_ISL were calibrated, and the number of correct matches found at a given error rate was the same as that found by PSI_BLAST. The advantage of this library is that it uses pairwise sequence comparison methods, such as FASTA or BLAST2, and can, therefore, be searched easily and, in many cases, much more quickly than an iterative multiple sequence comparison method. The procedure is roughly twenty times faster than PSI-BLAST for small genomes and several hundred times for large genomes such as C. elegans.Sequences can be submitted to the PDB_ISL servers athttp://stash.mrc-lmb.cam.ac.uk/PDB_ISL/ftp://ftp.ebi.ac.uk/pub/databases/pdb_isl/},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {283–289},
numpages = {7},
keywords = {structure assignment, homology, PSI-BLAST, PDB_ISL},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332567,
author = {Tomita, Masaru and Hashimoto, Kenta and Takahashi, Koichi and Matsuzaki, Yuri and Matsushima, Ryo and Yugi, Katsuyuki and Miyoshi, Fumihiko and Nakano, Hisako and Saito, Yusuke and Shimizu, S. and Nakayama, Yoichi},
title = {The E-CELL project: towards integrative simulation of cellular processes},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332567},
doi = {10.1145/332306.332567},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {290–298},
numpages = {9},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332568,
author = {Xu, Ying and Xu, Dong and Crawford, Oakley H. and Einstein, J. Ralph and Serpersu, Engin},
title = {Protein structure determination using protein threading and sparse NMR data (extended abstract)},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332568},
doi = {10.1145/332306.332568},
abstract = {It is well known that the NMR method for protein structure determination applies to small proteins and that its effectiveness decreases very rapidly as the molecular weight increases beyond about 30 kD. We have recently developed a method for protein structure determination that can fully utilize partial NMR data as calculation constraints. The core of the method is a threading algorithm that guarantees to find a globally optimal alignment between a query sequence and a template structure, under distance constraints specified by NMR/NOE data. Our preliminary tests have demonstrated that a small number of NMR/NOE distance restraints can significantly improve threading performance in both fold recognition and threading-alignment accuracy, and can possibly extend threading's scope of applicability from structural homologs to structural analogs. An accurate backbone structure generated by NMR-constrained threading can then provide a significant amount of structural information, equivalent to that provided by the NMR method with many NMR/NOE restraints; and hence can greatly reduce the amount of NMR data typically required for accurate structure determination. Our prelimenary study suggest that a small number of NOE restraints may suffice to determine adequately the all-atom structure when those restraints are incorporated in a procedure combining threading, modeling of loops and sidechains, and molecular dynamics simulation. Potentially, this new technique can expand NMR's capability to larger proteins.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {299–307},
numpages = {9},
keywords = {protein threading, protein structure determination, fold recognition, energy minimization, NMR},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332569,
author = {Yona, Golan and Levitt, Michael},
title = {A unified sequence-structure classification of protein sequences: combining sequence and structure in a map of the protein space},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332569},
doi = {10.1145/332306.332569},
abstract = {We analyze all known protein sequences in search for a global map of protein space that is consistent in terms of both sequence and structure. Our goal is to define clusters of homologous protein domains, beyond those detected by sequence-based methods alone, and then to build a three-dimensional (3D) model for each of the sequences that are homologous to sequences of known 3D structure. This analysis uses both sequence and structure based metrics in the analysis of all protein sequences in a non-redundant (NR) database, comprising all major sequence databases.The analysis starts from the sequences of the SCOP database domains, which have known three-dimensional structures These sequences are clustered first into families based on sequence similarity alone, without incorporating any information from the SCOP classification. Each sequence-based family is represented by a profile, and this profile is used to search the NR database, using PSI-BLAST. Since PSI-BLAST can lead to false similarities, several different indices of validity are used to control the procedure Each of the detected sequences is marked and a profile is built for the whole cluster of similar sequences. A 3D model is then built for each sequence in the cluster using an alignment made using the profile as well as the known structures of the SCOP representatives in the cluster Clusters based on SCOP domains are called type-I clusters In all we find 1421 type-I clusters with total of 168,431 sequences (44.5\% of our NR database)After all members of type-I clusters have been marked, we analyze the remaining sequences. The PSI-BLAST procedure is applied repeatedly, each time with a different query, to search what is left over from the previous run. This give type-II clusters, which may overlap.Type-I and type-II clusters are then grouped using higher level measures of similarity. Those pairs of clusters that contain the same common protein (significant overlap in membership), are marked first. The pairs of clusters are then compared using either a structure metric (when 3D structures are known) or a novel sequence profile metric, and clustered into superfamilies and “fold” families.This analysis avoids the limitation of classifications that are based just on sequence comparison, and allows us to construct a 3D model for a substantial portion of the sequences in the NR database.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {308–317},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

@inproceedings{10.1145/332306.332570,
author = {Zein, Alexander and Zimmer, Ralf and Lengauer, Thomas},
title = {A simple iterative approach to parameter optimization},
year = {2000},
isbn = {1581131860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/332306.332570},
doi = {10.1145/332306.332570},
abstract = {Various bioinformatics problems require optimizing several different properties simultaneously. For example, in the protein threading problem, a linear scoring function combines the values for different properties of possible sequence-to-structure alignments into a single score to allow for unambigous optimization. In this context, an essential question is how each property should be weighted. As the native structures are known for some sequences, the implied partial ordering on optimal alignments may be used to adjust the weights. To resolve the arising interdependence of weights and computed solutions, we propose a novel approach: iterating the computation of solutions (here: threading alignments) given the weights and the estimation of optimal weights of the scoring function given these solutions via a systematic calibration method. We show that this procedure converges to structurally meaningful weights, that also lead to significantly improved performance on comprehensive test data sets as measured in different ways. The latter indicates that the performance of threading can be improved in general.},
booktitle = {Proceedings of the Fourth Annual International Conference on Computational Molecular Biology},
pages = {318–327},
numpages = {10},
location = {Tokyo, Japan},
series = {RECOMB '00}
}

