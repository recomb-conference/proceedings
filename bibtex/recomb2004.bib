@inproceedings{10.1145/974614.974615,
author = {Nickerson, Deborah},
title = {SNPing in the human genome},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974615},
doi = {10.1145/974614.974615},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {1},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974616,
author = {Kimmel, Gad and Shamir, Ron},
title = {Maximum likelihood resolution of multi-block genotypes},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974616},
doi = {10.1145/974614.974616},
abstract = {We present a new algorithm for the problems of genotype phasing and block partitioning. Our algorithm is based on a new stochastic model, and on the novel concept of probabilistic common haplotypes. We formulate the goals of genotype resolving and block partitioning as a maximum likelihood problem, and solve it by an EM algorithm. When applied to real biological SNP data, our algorithm outperforms two state of the art phasing algorithms. Our algorithm is also considerably more sensitive and accurate than a previous method in predicting and identifying disease association.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {2–9},
numpages = {8},
keywords = {maximum likelihood, haplotyping, haplotype resolution, haplotype block, haplotype, genotype phasing, genotype, disease association, algorithm, SNP},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974617,
author = {Halperin, Eran and Karp, Richard M.},
title = {Perfect phylogeny and haplotype assignment},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974617},
doi = {10.1145/974614.974617},
abstract = {This paper is concerned with the reconstruction of perfect phylogenies from binary character data with missing values, and related problems of inferring complete haplotypes from haplotypes or genotypes with missing data. In cases where the problems considered are NP-hard we assume a rich data hypothesis under which they become tractable. Natural probabilistic models are introduced for the generation of character vectors, haplotypes or genotypes with missing data, and it is shown that these models support the rich data hypothesis. The principal results include: A near-linear time algorithm for inferring a perfect phylogeny from binary character data (or haplotype data) with missing values, under the rich data hypothesis;A quadratic-time algorithm for inferring a perfect phylogeny from genotype data with missing values with high probability, under certain distributional assumptions;Demonstration that the problems of maximum-likelihood inference of complete haplotypes from partial haplotypes or partial genotypes can be cast as minimum-entropy disjoint set cover problems;In the case where the haplotypes come from a perfect phylogeny, a representation of the set cover problem as minimum-entropy covering of subtrees of a tree by nodes;An exact algorithm for minimum-entropy subtree covering, and demonstration that it runs in polynomial time when the subtrees have small diameter;Demonstration that a simple greedy approximation algorithm solves the minimum-entropy subtree covering problem with relative error tending to zero when the number of partial haplotypes per complete haplotype is large;An asymptotically consistent method of estimating the frequencies of the complete haplotypes in a perfect phylogeny, under an iid model for the distribution of missing data;Computational results on real data demonstrating the effectiveness of a the greedy algorithm for inferring haplotypes from genotypes with missing data, even in the absence of a perfect phylogeny..},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {10–19},
numpages = {10},
keywords = {phasing, perfect phylogeny, haplotypes, entropy},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974618,
author = {Li, Jing and Jiang, Tao},
title = {An exact solution for finding minimum recombinant haplotype configurations on pedigrees with missing data by integer linear programming},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974618},
doi = {10.1145/974614.974618},
abstract = {We study the problem of reconstructing haplotype configurations from genotypes on pedigree data with missing alleles under the Mendelian law of inheritance and the minimum recombination principle, which is important for the construction of haplotype maps and genetic linkage/association analysis. Our previous results show that the problem of finding a minimum-recombinant haplotype configuration (MRHC) is in general NP-hard. The existing algorithms for MRHC either are heuristic in nature and cannot guarantee optimality, or only work under some restrictions (on e.g. the size and structure of the input pedigree, the number of marker loci, the number of recombinants in the pedigree, etc.). In addition, most of them cannot handle data with missing alleles and, for those that do consider missing data, they usually do not perform well in terms of minimizing the number of recombinants when a significant fraction of alleles are missing. In this paper, we develop an effective integer linear programming (ILP) formulation of the MRHC problem with missing data and a branch-and-bound strategy that utilizes a partial order relationship (and some other special relationships) among variables to decide the branching order. The partial order relationship is discovered in the preprocessing of constraints by considering unique properties in our ILP formulation. A directed graph is built based on the variables and their partial order relationship. By identifying and collapsing the strongly connected components in the graph, we may greatly reduce the size of an ILP instance. Non-trivial (lower and upper) bounds on the optimal number of recombinants are introduced at each branching node to effectively prune the search tree. When multiple solutions exist, a best haplotype configuration is selected based on a maximum likelihood approach. Our results on simulated data show that the algorithm could recover haplotypes with 50 loci from a pedigree of size 29 in seconds on a standard PC. Its accuracy is more than 99.8\% for data with no missing alleles and 98.3\% for data with 20\% missing alleles in terms of correctly recovered phase information at each marker locus. As an application of our algorithm to real data, we present some test results on reconstructing haplotypes from a genome-scale SNP data set consisting of 12 pedigrees that have 0.8\% to 14.5\% missing alleles.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {20–29},
numpages = {10},
keywords = {recombination, pedigree analysis, missing data imputation, integer linear programming, haplotyping, branch-and-bound algorithm},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974619,
author = {Sankoff, David and Trinh, Phil},
title = {Chromosomal breakpoint re-use in the inference of genome sequence rearrangement},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974619},
doi = {10.1145/974614.974619},
abstract = {In order to apply gene-order rearrangement algorithms to the comparison of genome sequences, Pevzner and Tesler [9] bypass gene finding and ortholog identification, and use the order of homologous blocks of unannotated sequence as input. The method excludes blocks shorter than a threshold length and ignores small block-internal rearrangements. Here we investigate possible biases introduced by eliminating and amalgamating short blocks, focusing on the notion of "breakpoint re-use" introduced by these authors. Analytic and simulation methods show that re-use is very sensitive to threshold size and to parameters of the rearrangement process. As is pertinent to the comparison of mammalian genomes, large thresholds in the context of high rates of small rearrangements risk randomizing the comparison completely. We suggest a number of mathematical, algorithmic and statistical lines for further developing the Pevzner-Tesler approach.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {30–35},
numpages = {6},
keywords = {synteny blocks, rearrangements, inversion, evolution, comparative genomics, breakpoints, Hannenhalli-Pevzner algorithm},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974620,
author = {Beerenwinkel, Niko and Rahnenf\"{u}hrer, J\"{o}rg and D\"{a}umer, Martin and Hoffmann, Daniel and Kaiser, Rolf and Selbig, Joachim and Lengauer, Thomas},
title = {Learning multiple evolutionary pathways from cross-sectional data},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974620},
doi = {10.1145/974614.974620},
abstract = {We introduce a mixture model of trees to describe evolutionary processes that are characterized by the accumulation of permanent genetic changes. The basic building block of the model is a directed weighted tree that generates a probability distribution on the set of all patterns of genetic events. We present an EM-like algorithm for learning a mixture model of K trees and show how to determine K with a maximum likelihood approach. As a case study we consider the accumulation of mutations in the HIV-1 reverse transcriptase that are associated with drug resistance. The fitted model is statistically validated as a density estimator and the stability of the model topology is analyzed. We obtain a generative probabilistic model for the development of drug resistance in HIV that agrees with biological knowledge. Further applications and extensions of the model are discussed.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {36–44},
numpages = {9},
keywords = {tree models, mutational pathways, mixture models, bayesian networks, HIV drug resistance, EM algorithm},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974621,
author = {Karp, Richard M.},
title = {Algorithms for inferring cis-regulatory structures and protein interaction networks},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974621},
doi = {10.1145/974614.974621},
abstract = {A major focus of functional genomics today is the discovery of the interactions between genes and proteins that regulate the transcription of genes and the responses of cells to external signals. The speaker will describe his recent efforts with several coworkers to solve pieces of this puzzle. The work divides into several parts: A new approach to the recognition of transcription-factor binding sites, based on the principle that transcription factors divide naturally into families such as the leucine zippers and the zinc fingers, and that the binding site motifs for transcription factors within the same family have common features. These features may be obscure at the sequence level, but can be characterized at a higher level of description. By discovering and modeling such meta-sequence features one can improve the sensitivity and specificity with which binding sites can be determined for transcription factors within a family. [5], [6]An algorithm and an associated web-based tool for finding recurrent cis-regulatory modules in the promoter regions of human genes. Each such module consists of a set of transcription factors that often bind to the same promoter regions and collectively enhance or inhibit the transcription of the corresponding genes. [4]An algorithm for minimizing the number of gene perturbation experiments required to reconstruct signal transduction pathways whose regulatory structures can be described within the mathematical framework of chain functions. [1]Algorithms for discovering protein complexes and regulatory pathways that are conserved in evolution, using protein sequence data and protein-protein interaction data for two or more organisms. [2], [3].},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {45},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974622,
author = {Lilien, Ryan H. and Stevens, Brian W. and Anderson, Amy C. and Donald, Bruce R.},
title = {A novel ensemble-based scoring and search algorithm for protein redesign, and its application to modify the substrate specificity of the gramicidin synthetase A phenylalanine adenylation enzyme},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974622},
doi = {10.1145/974614.974622},
abstract = {Realization of novel molecular function requires the ability to alter molecular complex formation. Enzymatic function can be altered by changing enzyme-substrate interactions via modification of an enzyme's active site. A redesigned enzyme may either perform a novel reaction on its native substrates or its native reaction on novel substrates. A number of computational approaches have been developed to address the combinatorial nature of the protein redesign problem. These approaches typically search for the global minimum energy conformation among an exponential number of protein conformations. We present a novel algorithm for protein redesign, which combines a statistical mechanics-derived ensemble-based approach to computing the binding constant with the speed and completeness of a branch-and-bound pruning algorithm. In addition, we developed an efficient deterministic approximation algorithm, capable of approximating our scoring function to arbitrary precision. In practice, the approximation algorithm decreases the execution time of the mutation search by a factor of ten. To test our method, we examined the Phe-specific adenylation domain of the non-ribosomal peptide synthetase gramicidin synthetase A (GrsA-PheA). Ensemble scoring, using a rotameric approximation to the partition functions of the bound and unbound states for GrsA-PheA, is first used to predict binding of the wildtype protein and a previously described mutant (selective for leucine), and second, to switch the enzyme specificity toward leucine, using two novel active site sequences computationally predicted by searching through the space of possible active site mutations. The top scoring in silico mutants were created in the wetlab and dissociation / binding constants were determined by fluorescence quenching. These tested mutations exhibit the desired change in specificity from Phe to Leu. Our ensemble-based algorithm which flexibly models both protein and ligand using rotamer-based partition functions, has application in enzyme redesign, the prediction of protein-ligand binding, and computer-aided drug design.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {46–57},
numpages = {12},
keywords = {protein-ligand binding, protein flexibility, protein design, non-ribosomal peptide synthetase, molecular ensemble, fluorescence binding assay, enzyme design},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974623,
author = {Bailey-Kellogg, Chris and Chainraj, Sheetal and Pandurangan, Gopal},
title = {A random graph approach to NMR sequential assignment},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974623},
doi = {10.1145/974614.974623},
abstract = {Nuclear magnetic resonance (NMR) spectroscopy allows scientists to study protein structure, dynamics, and interactions in solution. A necessary first step for such applications is determining the resonance assignment, mapping spectral data to atoms and residues in the primary sequence. Automated resonance assignment algorithms rely on information regarding connectivity (e.g. through-bond atomic interactions) and amino acid type, typically using the former to determine strings of connected residues and the latter to map those strings to positions in the primary sequence. Significant ambiguity exists in both connectivity and amino acid type, and different algorithms have combined the information in two phases (find short unambiguous strings then align) or simultaneously (align while extending strings). This paper focuses on the information content available in connectivity alone, allowing for ambiguity rather than handling only unambiguous strings, and complements existing work on the information content in amino acid type.In this paper, we develop a novel random-graph theoretic framework for algorithmic analysis of NMR sequential assignment. Our random graph model captures the structure of chemical shift degeneracy (a key source of connectivity ambiguity). We then give a simple and natural randomized algorithm for finding an optimum sequential cover. The algorithm naturally and efficiently reuses substrings while exploring connectivity choices; it overcomes local ambiguity by enforcing global consistency of all choices. We employ our random graph model to analyze our algorithm, and show that it can provably tolerate a relatively large ambiguity while still giving expected optimal performance in polynomial time. To study the algorithm's performance in practice, we tested it on experimental data sets from a variety of proteins and experimental set-ups. The algorithm was able to overcome significant noise and local ambiguity and consistently identify significant sequential fragments.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {58–67},
numpages = {10},
keywords = {randomized algorithm, random graph model, protein structure determination, probabilistic analysis, nuclear magnetic resonance (NMR) spectroscopy, hamiltonian path, chemical shift degeneracy, automated sequential resonance assignment},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974624,
author = {Zhao, Xiaoyue and Huang, Haiyan and Speed, Terence P.},
title = {Finding short DNA motifs using permuted markov models},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974624},
doi = {10.1145/974614.974624},
abstract = {Many short DNA motifs such as transcription factor binding sites (TFBS) and splice sites exhibit strong local as well as non-local dependence. We introduce permuted variable length Markov models (PVLMM) which could capture the potentially important dependencies among positions, and apply them to the problem of detecting splice and TFB sites. They have been satisfactory from the viewpoint of prediction performance, and also give ready biological interpretations of the sequence dependence observed. The issue of model selection is also studied.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {68–75},
numpages = {8},
keywords = {weight matrix models, transcription factor binding sites, splice sites, permuted variable length Markov models, model selection, maximal dependence decomposition, Jeffreys mixture},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974625,
author = {Sun, Yanni and Buhler, Jeremy},
title = {Designing multiple simultaneous seeds for DNA similarity search},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974625},
doi = {10.1145/974614.974625},
abstract = {The challenge of similarity search in massive DNA sequence databases has inspired major changes in BLAST-style alignment tools, which accelerate search by inspecting only pairs of sequences sharing a common short "seed," or pattern of matching residues. Some of these changes raise the possibility of improving search performance by probing sequence pairs with several distinct seeds, any one of which is sufficient for a seed match. However, designing a set of seeds to maximize their combined sensitivity to biologically meaningful sequence alignments is computationally difficult, even given recent advances [16, 6] in designing single seeds.This work describes algorithmic improvements to seed design that address the problem of designing a set of n seeds to be used simultaneously. We give a new local search method to optimize the sensitivity of seed sets. The method relies on efficient incremental computation of the probability that an alignment contains a match to a seed π, given that it has already failed to match any of the seeds in a set π. We demonstrate experimentally that multi-seed designs, even with relatively few seeds, can be significantly more sensitive than even optimized single-seed designs.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {76–84},
numpages = {9},
keywords = {similarity search, seed design, genomic DNA, biosequence comparison, Mandala},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974626,
author = {Kececioglu, John and Starrett, Dean},
title = {Aligning alignments exactly},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974626},
doi = {10.1145/974614.974626},
abstract = {A basic computational problem that arises in both the construction and local-search phases of the best heuristics for multiple sequence alignment is that of aligning the columns of two multiple alignments. When the scoring function is the sum-of-pairs objective and induced pairwise alignments are evaluated using linear gap-costs, we call this problem Aligning Alignments. While seemingly a straightforward extension of two-sequence alignment, we prove it is actually NP-complete. As explained in the paper, this provides the first demonstration that minimizing linear gap-costs, in the context of multiple sequence alignment, is inherently hard.We also develop an exact algorithm for Aligning Alignments that is remarkably efficient in practice, both in time and space. Even though the problem is NP-complete, computational experiments on both biological and simulated data show we can compute optimal alignments for all benchmark instances in two standard datasets, and solve very-large random instances with highly-gapped sequences.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {85–96},
numpages = {12},
keywords = {sum of pairs, multiple sequence alignment, linear gap costs, exact algorithms},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974627,
author = {Winzeler, Elizabeth A. and Le Roch, Karine G. and Zhou, Yingyao and Blair, Peter L. and Grainger, Muni and Moch, J. Kathleen and Haynes, J. David and De la Vega, Patricia and Holder, Anthony A. and Batalov, Serge and Carucci, Daniel J.},
title = {Systems biology and malaria},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974627},
doi = {10.1145/974614.974627},
abstract = {Malaria is the cause of significant global morbidity and mortality with 300-500 million cases annually. Despite its disease burden relatively little is known about the molecular biology of the pathogen that causes malaria. For example, the completion of the genome sequence of Plasmodium falciparum, the species responsible for the most severe form of human malaria revealed that only 35\% of the genes code for proteins with an identifiable function. In addition, little is known about how transcription and translation are regulated. The absence of routine genetic tools for studying Plasmodium parasites suggests that these numbers are unlikely to change quickly if conventional, serial, biological methods are used to study the parasite. We are using high-density oligonucleotide arrays and informatic methods to study the genome of the malaria parasite with the goals of understanding how expression is regulated, functionally cataloging the genome, discovering allelic variation and identifying new therapeutic targets. We have shown that genes with highly correlated levels and temporal patterns of expression are often involved in similar functions or cellular processes suggesting that expression profiling can be used to rapidly predict function. In addition we find that there is good correlation between protein levels and transcript levels, suggesting that regulation of expression occurs transcriptionally. Analysis of whole-genome transcription patterns reveals that the chromosome is organized into regions that are transcriptionally active and transcriptionally silent in the intraerythrocytic stage of the parasite's lifecycle. Thus, both the timing and the relative level of transcription in the parasite is organized into position-dependent domains suggesting that transcription may be regulated at least partially at the level of chromatin structure.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {97},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974628,
author = {Wu, Zhijin and Irizarry, Rafael A.},
title = {Stochastic models inspired by hybridization theory for short oligonucleotide arrays},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974628},
doi = {10.1145/974614.974628},
abstract = {High density oligonucleotide expression arrays are a widely used tool for the measurement of gene expression on a large scale. Affymetrix GeneChip arrays appear to dominate this market. These arrays use short oligonucleotides to probe for genes in an RNA sample. Due to optical noise, non-specific hybridization, probe-specific effects, and measurement error, ad-hoc measures of expression, that summarize probe intensities, can lead to imprecise and inaccurate results. Various researchers have demonstrated that expression measures based on simple statistical models can provide great improvements over the ad-hoc procedure offered by Affymetrix. Recently, physical models based on molecular hybridization theory, have been proposed as useful tools for prediction of, for example, non-specific hybridization. These physical models show great potential in terms of improving existing expression measures. In this paper we suggest that the system producing the measured intensities is too complex to be fully described with these relatively simple physical models and we propose empirically motivated stochastic models that compliment the above mentioned molecular hybridization theory to provide a comprehensive description of the data. We discuss how the proposed model can be used to obtain improved measures of expression useful for the data analysts.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {98–106},
numpages = {9},
keywords = {stochastic models, physical models, microarrays, background adjustment, affymetrix probe-level data},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974629,
author = {Ledent, Sabrina and Robin, St\'{e}phane},
title = {Checking homogeneity of motifs' distribution in heterogenous sequences},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974629},
doi = {10.1145/974614.974629},
abstract = {Studying the distribution of a motif along sequences may help to understand its biological function, or to detect regions of interest. A statistical model is needed to assess the significancy of the observed distribution. We propose an heterogenous compound Poisson process to model the possibility of overlap between occurrences and some heterogeneity of the sequence a priori known. The parameters estimation procedure is described and tests of homogenous sub-models are proposed. We also consider the detection of rich regions using either cumulated distances or moving intervals, via an homogenization technique. Illustrations of the method are given with applications to bacterial genomes.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {107–114},
numpages = {8},
keywords = {statistics of motifs, scan statistics, heterogeneity, compound poisson model},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974630,
author = {Eskin, Eleazar},
title = {From profiles to patterns and back again: a branch and bound algorithm for finding near optimal motif profiles},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974630},
doi = {10.1145/974614.974630},
abstract = {An important part of deciphering gene regulatory mechanisms is discovering transcription factor binding sites. In many cases, these sites can be detected because they are often overrepresented in genomic sequences. The detection of the overrepresented signals in sequences, or motif-finding has become a central problem in computational biology. There are two major computational frameworks for attacking the motif finding problem which differ in their representation of the signals. The most popular is the profile or PSSM (Position Specific Scoring Matrix) representation. The goal of these algorithms is to obtain probabilistic representations of the overrepresented signals. Another is the consensus pattern or pattern with mismatches representation which represents a signal as discrete consensus pattern and allows some mismatches to occur in each instance of the pattern. The advantage of profiles is the expressiveness of their representation while the advantage of the consensus pattern approach is the existence of efficient algorithms that guarantee discovery of the best patterns. In this paper we present a unified framework for motif finding which encompasses both the profile representation and the consensus pattern representation. We prove that the problem of discovering the best profiles can be solved by considering a degenerate version of the problem of finding the best consensus patterns. The main advantage of our framework is that it motivates a novel algorithm, MITRA-PSSM, which discovers profiles, yet provides some of the guarantees of discovering the best signals. The algorithm searches for best profiles with respect to information content which is the same criterion of popular algorithms such as MEME and CONSENSUS. MITRA-PSSM is specifically designed for searching for profiles in this framework and introduces a novel notion of scoring consensus patterns, discrete information content. MITRA-PSSM is available for public use via webserver at http://www.calit2.net/compbio/mitra/.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {115–124},
numpages = {10},
keywords = {transcription factor binding sites, profiles, patterns, motif-finding},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974631,
author = {Chin, Francis Y. L. and Leung, Henry C. M. and Yiu, S. M. and Lam, T. W. and Rosenfeld, Roni and Tsang, W. W. and Smith, David K. and Jiang, Y.},
title = {Finding motifs for insufficient number of sequences with strong binding to transcription facto},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974631},
doi = {10.1145/974614.974631},
abstract = {Finding motifs is an important problem in computational biology. Our paper makes two major contributions to this problem. Firstly, we better characterize the types of problem instances that cannot be solved by most existing methods of finding motifs. Secondly, we introduce a different method, which is shown to succeed for various problem instances for which popular existing methods fail.Most existing computational methods to finding motifs are based on the strong-signal model wherein only strong-signal sequences (i.e. those that are known to contain binding sites very similar to the motif) are considered as input and weak-signal sequences (i.e. those do not contain any sub-string similar to the motif) are disregarded.Buhler and Tompa have studied the limitations of methods based on the strong-signal model. They characterized the problem instances for which the motif is unlikely to be found in terms of the number of input (strong-signal) sequences needed under the assumption that each input sequence contains exactly one binding site. They further gave a method to calculate the minimum number of input sequences required.We re-characterize the limitations of the strong-signal model in terms of the minimum total number of binding sites, rather than the minimum number of strong-signal sequences, required to be in the input data set. We use a probability matrix to represent a motif instead of a string pattern to calculate the minimum total number of binding sites required. This new characterization is shown to be more general and realistic.Next, we introduce a more general and realistic energy-based model, which considers all available sequences (including weak-signal sequences) with varying degrees of binding strength to the transcription factors (as measured experimentally by observed color intensity). Given varying degrees of binding strength, our model can consider sequences ranging from those that contain more than one binding site to those that are weak sequences. By treating sequences with different degrees of binding strength differently, we develop a heuristic algorithm called EBMF (Energy-Based Motif Finding algorithm) using an EM-like approach to find motifs under our model. This EBMF algorithm can find motifs for data sets that do not even have the required minimum number of binding sites as previously derived for the strong-signal model. Our algorithm compares favorably with common motif-finding programs AlignACE and MEME, which are based on the strong-signal model. In particular, for some simulated and real data sets, our algorithm finds the motif when both AlignACE and MEME fail to do so.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {125–132},
numpages = {8},
keywords = {transcription factor, motif finding, binding energy, DNA microarray},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974632,
author = {Policriti, Alberto and Vitacolonna, Nicola and Morgante, Michele and Zuccolo, Andrea},
title = {Structured motifs search},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974632},
doi = {10.1145/974614.974632},
abstract = {In this paper we describe an algorithm for the localization of structured models, i.e. sequences of (simple) motifs and distance constraints. It basically combines standard pattern matching procedures with a constraint satisfaction solver, and it has the ability, not present in similar tools, to search for partial matches. A significant feature of our approach, especially in terms of efficiency for the application context, is that the (potentially) exponentially many solutions to the considered problem are represented in compact form as a graph. Moreover, the time and space necessary to build the graph are linear in the number of occurrences of the component patterns.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {133–139},
numpages = {7},
keywords = {structured motifs, interval constraints, graph data structures},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974633,
author = {McGinnis, William},
title = {Evolutionary change in developmental genetic networks},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974633},
doi = {10.1145/974614.974633},
abstract = {The different combinations of genes that are active in different cells control the development and diversity of multicellular organisms. The codes that control this process, written in both cis-regulatory and protein-coding DNA sequence, are poorly understood. Decoding those sequences will require many experimental and bioinformatic approaches. One approach that will be useful is discovering the nodal control points that change when genetic networks evolve to change form and function. Recent discoveries will be described on the molecular changes in a network that modifies limb number during arthropod evolution. Another important experimental approach useful to decoding is the determination of precise gene expression patterns during model organism development, including which expression patterns are conserved and which are variable. A new approach has been developed that involves assigning spectral barcodes to many different nascent transcripts in developing animal nuclei. This will allow the rapid determination of precise spatial domains of transcriptional activation, and the construction of virtual embryos with complete maps of combinatorial gene expression.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {140},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974634,
author = {Segal, Eran and Sharan, Roded},
title = {A discriminative model for identifying spatial cis-regulatory modules},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974634},
doi = {10.1145/974614.974634},
abstract = {Transcriptional regulation is mediated by the coordinated binding of transcription factors to the upstream region of genes. In higher eukaryotes, the binding sites of cooperating transcription factors are organized into short sequence units, called cis-regulatory modules. In this paper we propose a method for identifying modules of transcription factor binding sites in a set of co-regulated genes, using only the raw sequence data as input. Our method is based on a novel probabilistic model that describes the mechanism of cis-regulation, including the binding sites of cooperating transcription factors, the organization of these binding sites into short sequence modules, and the regulation of a gene by its modules. We show that our method is successful in discovering planted modules in simulated data and known modules in yeast. More importantly, we applied our method to a large collection of human gene sets, and found 83 significant cis-regulatory modules, which included 36 known motifs and many novel ones. Thus, our results provide one of the first comprehensive compendiums of putative cis-regulatory modules in human.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {141–149},
numpages = {9},
keywords = {transcriptional regulation, probabilistic model, cis-regulatory module},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974635,
author = {Farach-Colton, Martin and Huang, Yang and Woolford, John L. L.},
title = {Discovering temporal relations in molecular pathways using protein-protein interactions},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974635},
doi = {10.1145/974614.974635},
abstract = {The availability of large-scale protein-protein interaction data provides us with many opportunities to study molecular pathways involving proteins. In this paper we propose to mine temporal relations in molecular pathways by protein-protein interaction data. In particular, we model the assembly pathways of protein complexes with interval graphs and determine the temporal order of joining the pathway for proteins by ordering the vertices in the interaction graph. We develop a tool called Xronos to perform such a computation. We then apply Xronos to the ribosome assembly pathway and present validation results for the obtained ordering. The results are promising and show the potential usage for Xronos in the study of molecular pathways.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {150–156},
numpages = {7},
keywords = {vertex ordering, ribosomal assembly pathway, protein-protein interaction, probe interval graphs, molecular pathways, interval graphs},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974636,
author = {Peng, Hanchuan and Myers, Eugene W.},
title = {Comparing in situ mRNA expression patterns of drosophila embryos},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974636},
doi = {10.1145/974614.974636},
abstract = {In situ staining of a target mRNA at several time points during the development of a D. melanogaster embryo gives one a detailed spatio-temporal view of the expression pattern of a given gene. We have developed algorithms and software for analyzing a database of such images with the goal of being able to identify coordinately expressed genes and further our understanding of cis-regulatory control during embryogenesis. Our approach combines measures of similarity at both the global and local levels, based on Gaussian Mixture Model (GMM) decompositions. At the global level, the observed distribution of pixel values is quantized using an adaptive GMM decomposition and then quantized images are compared using mutual information. At the local level, we decompose quantized images into 2-dimensional Gaussian kernels or "blobs" and then develop a blob-set matching method to search for the best matching traits in different pattern-images. A hybrid scoring method is proposed to combine both global and local matching results. We further develop a voting scheme to search for genes with similar spatial staining patterns over the time course of embryo development. To evaluate the effectiveness of our approach, we compare it with several global image matching schemes and a controlled vocabulary method. We then apply our method to 4400 images of 136 genes to detect potentially co-regulated genes that have similar spatio-temporal patterns, using expert-annotation to evaluate our results.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {157–166},
numpages = {10},
keywords = {in situ hybridization, image matching, gene expression, gaussian mixture model, embryogenesis, drosophila},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974637,
author = {Battle, Alexis and Segal, Eran and Koller, Daphne},
title = {Probabilistic discovery of overlapping cellular processes and their regulation},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974637},
doi = {10.1145/974614.974637},
abstract = {Many of the functions carried out by a living cell are regulated at the transcriptional level, to ensure that genes are expressed when they are needed. Thus, to understand biological processes, it is thus necessary to understand the cell's transcriptional network. In this paper, we propose a novel probabilistic model of gene regulation for the task of identifying overlapping biological processes and the regulatory mechanism controlling their activation. A key feature of our approach is that we allow genes to participate in multiple processes, thus providing a more biologically plausible model for the process of gene regulation. We present an algorithm to learn this model automatically from data, using only genome-wide measurements of gene expression as input. We compare our results to those obtained by other approaches, and show significant benefits can be gained by modeling both the organization of genes into overlapping cellular processes and the regulatory programs of these processes. Moreover, our method successfully grouped genes known to function together, recovered many regulatory relationships that are known in the literature, and suggested novel hypotheses regarding the regulatory role of previously uncharacterized proteins.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {167–176},
numpages = {10},
keywords = {probabilistic relational models, gene regulation, cellular processes},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974638,
author = {Siepel, Adam and Haussler, David},
title = {Computational identification of evolutionarily conserved exons},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974638},
doi = {10.1145/974614.974638},
abstract = {Phylogenetic hidden Markov models (phylo-HMMs) have recently been proposed as a means for addressing a multi-species version of the ab initio gene prediction problem. These models allow sequence divergence, a phylogeny, patterns of substitution, and base composition all to be considered simultaneously, in a single unified probabilistic model. Here, we apply phylo-HMMs to a restricted version of the gene prediction problem in which individual exons are sought that are evolutionarily conserved across a diverse set of species. We discuss two new methods for improving prediction performance: (1) the use of context-dependent phylogenetic models, which capture phenomena such as a strong CpG effect in noncoding regions and a preference for synonymous rather than nonsynonymous substitutions in coding regions; and (2) a novel strategy for incorporating insertions and deletion (indels) into the state-transition structure of the model, which captures the different characteristic patterns of alignment gaps in coding and noncoding regions. We also discuss the technique, previously used in pairwise gene predictors, of explicitly modeling conserved noncoding sequence to help reduce false positive predictions. These methods have been incorporated into an exon prediction program called ExoniPhy, and tested with two large data sets. Experimental results indicate that all three methods produce significant improvements in prediction performance. In combination, they lead to prediction accuracy comparable to that of some of the best available gene predictors, despite several limitations of our current models.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {177–186},
numpages = {10},
keywords = {phylogenetic hidden markov model, gene prediction},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974639,
author = {Chatterji, Sourav and Pachter, Lior},
title = {Multiple organism gene finding by collapsed gibbs sampling},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974639},
doi = {10.1145/974614.974639},
abstract = {The Gibbs sampling method has been widely used for sequence analysis after it was successfully applied to the problem of identifying regulatory motif sequences upstream of genes. Since then numerous variants of the original idea have emerged, however in all cases the application has been to finding short motifs in collections of short sequences (typically less than 100 nucleotides long). In this paper we introduce a Gibbs sampling approach for identifying genes in multiple large genomic sequences up to hundreds of kilobases long. This approach leverages the evolutionary relationships between the sequences to improve the gene predictions, without explicitly aligning the sequences. We have applied our method to the analysis of genomic sequence from 14 genomic regions, totaling roughly 1.8Mb of sequence in each organism. We show that our approach compares favorably with existing ab-initio approaches to gene finding, including pairwise comparison based gene prediction methods which make explicit use of alignments. Furthermore, excellent performance can be obtained with as little as 4 organisms, and the method overcomes a number of difficulties of previous comparison based gene finding approaches: it is robust with respect to genomic rearrangements, can work with draft sequence, and is fast (linear in the number and length of the sequences). It can also be seamlessly integrated with Gibbs sampling motif detection methods.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {187–193},
numpages = {7},
keywords = {hidden markov model, gibbs sampling, gene finding},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974640,
author = {Nowak, Martin},
title = {Somatic evolution of cancer},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974640},
doi = {10.1145/974614.974640},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {194},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974641,
author = {Erdmann, Michael A.},
title = {Protein similarity from knot theory and geometric convolution},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974641},
doi = {10.1145/974614.974641},
abstract = {Shape similarity is one of the most elusive and intriguing questions of nature and mathematics. Proteins provide a rich domain in which to test theories of shape similarity. Proteins can match at different scales and in different arrangements. Sometimes the detection of common local structure is sufficient to infer global alignment of two proteins; at other times it provides false information. Proteins with very low sequence identity may share large substructures, or perhaps just a central core. There are even examples of proteins with nearly identical primary sequence in which α-helices have become Β-sheets.Shape similarity can be formulated (i) in terms of global metrics, such as RMSD or Hausdorff distance, (ii) in terms of subgraph isomorphisms, such as the detection of shared substructures with similar relative locations, or (iii) purely topologically, in terms of the cohomology induced by structure preserving transformations. Existing protein structure detection programs are built on the first two types of similarity. The third forms the foundations of knot theory.The thesis of this paper is: Protein similarity detection leads naturally to an algorithm operating at the metric, relational, and homotopic scales. The paper introduces a definition of similarity based on atomic motions that preserve local backbone topology without incurring significant distance errors. Such motions are motivated by the physical requirements for rearranging subsequences of a protein. Similarity detection then seeks rigid body motions able to overlay pairs of substructures, each related by a substructure-preserving motion, without necessarily requiring global structure preservation. This definition is general enough to span a wide range of questions: One can ask for full rearrangement of one protein into another while preserving global topology, as in drug design; or one can ask for rearrangements of sets of smaller substructures, each of which preserves local but not global topology, as in protein evolution.In the appendix, we exhibit an algorithm for answering the general question. That algorithm has the complexity of robot motion planning. In the text, we consider a more common case in which one seeks protein similarity by rearrangements of relatively short peptide segments. We exhibit an algorithm based on writhing numbers that runs in time O(n2) to O(n4). We define and use a new datastructure, called geometric self-convolution, within this algorithm.Contributions: We believe that this is the first paper to consider carefully the need for combining metric and homotopic qualities in seeking protein similarity. We provide a parameterized definition of similarity that leads naturally to a metric in protein space. We exhibit algorithms for computing the metric and detecting similarity. We report results obtained with three pairs of proteins, each pair exhibiting different typical characteristics.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {195–204},
numpages = {10},
keywords = {writhing, robot motion planning, protein structure, knot theory, homotopy, homology},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974642,
author = {Ban, Yih-En Andrew and Edelsbrunner, Herbert and Rudolph, Johannes},
title = {Interface surfaces for protein-protein complexes},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974642},
doi = {10.1145/974614.974642},
abstract = {Protein-protein interactions, which form the basis for most cellular processes, result in the formation of protein interfaces. Believing that the local shape of proteins is crucial, we take a geometric approach and present a definition of an interface surface formed by two or more proteins. We also present an algorithm and study the geometric and topological properties of these surfaces, thus paving the way for future biochemical studies of protein-protein interactions.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {205–212},
numpages = {8},
keywords = {voronoi diagrams, protein interaction, interface surfaces, geometric and topological algorithms, filtrations},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974643,
author = {Pevzner, Pavel A. and Tang, Haixu and Tesler, Glenn},
title = {De novo repeat classification and fragment assembly},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974643},
doi = {10.1145/974614.974643},
abstract = {Repetitive sequences make up a significant fraction of almost any genome and an important and still open question in bioinformatics is how to represent all repeats in DNA sequences. We propose a radically new approach to repeat classification that is motivated by the fundamental topological notion of quotient spaces. A torus or Klein bottle are examples of quotient spaces that can be obtained from a square by gluing some points. Our new repeat classification algorithm is based on the observation that the alignment-induced quotient space of a DNA sequence compactly represents all sequence repeats. This observation leads to a simple and efficient solution of the repeat classification problem as well as new approaches to fragment assembly and multiple alignment.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {213–222},
numpages = {10},
keywords = {sequence assembly, repeat analysis, multiple alignment},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974644,
author = {Wexler, Ydo and Yakhini, Zohar and Kashi, Yechezkel and Geiger, Dan},
title = {Finding approximate tandem repeats in genomic sequences},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974644},
doi = {10.1145/974614.974644},
abstract = {An efficient algorithm is presented for detecting approximate tandem repeats in genomic sequences. The algorithm is based on a flexible statistical model which allows a wide range of definitions of approximate tandem repeats. The ideas and methods underlying the algorithm are described and examined and its effectiveness on genomic data is demonstrated.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {223–232},
numpages = {10},
keywords = {trf, teiresias, tandem repeats, pattern discovery, DNA satellites, DNA repeats},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974645,
author = {Lippert, Ross A. and Zhao, Xiaoyue and Florea, Liliana and Mobarry, Clark and Istrail, Sorin},
title = {Finding anchors for genomic sequence comparison},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974645},
doi = {10.1145/974614.974645},
abstract = {Recent sequencing of the human and other mammalian genomes has brought about the necessity to align them, to identify and characterize their commonalities and differences. Programs that align whole genomes generally use a seed-and-extend technique, starting from exact or near-exact matches and selecting a reliable subset of these, called anchors, and then filling in the remaining portions between the anchors using a combination of local and global alignment algorithms, but their choices for the parameters so far have been primarily heuristic. We present a statistical framework and practical methods for selecting a set of matches that is both sensitive and specific and can constitute a reliable set of anchors for a one-to-one mapping of two genomes from which a whole-genome alignment can be built. Starting from exact matches, we introduce a novel per-base repeat annotation, the $Z$-score, from which noise and repeat filtering conditions are explored. Dynamic programming-based chaining algorithms are also evaluated as context-based filters. We apply the methods described here to the comparison of two progressive assemblies of the human genome, NCBI build 28 and build 34 http://genome.ucsc.edu), and show that a significant portion of the two genomes can be found in selected exact matches, with very limited amount of sequence duplication.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {233–241},
numpages = {9},
keywords = {whole-genome alignments, suffix trees, MUMs},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974646,
author = {Fire, Andrew},
title = {RNAi, genome ultrastructure, and other unexpected tales from the analysis of genetic silencing},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974646},
doi = {10.1145/974614.974646},
abstract = {The genetic landscape faced by a living cell is constantly changing. Developmental transitions, environmental shifts, and pathogenic invasions lend a dynamic character to both the genome and its activity pattern. A variety of natural mechanisms are utilized by cells adapting to genetic change. These include normal developmental mechanisms and a subset of defense systems for responding to pathogens. At the root of these studies are questions of how a cell can distinguish "self" versus "nonself" and "wanted" versus "unwanted" gene expression.Investigations of gene silencing in our lab and elswhere have identified a number of structural features that provide an indication of unwanted nucleic acid. One of these features has been double stranded RNA (dsRNA). Absent during "normal" gene expression, dsRNA is an essential component in the life cycle of most viruses. By flagging dsRNA as an indicator of unwanted RNA replication, and by scrupulously avoiding the production of dsRNA during most normal gene expression, the cell acquires a modicum of protection from viral infection. The mechanism by which dsRNA segments are utilized to trigger silencing of homologous genes, termed RNAi, has been a focus of intensive work at many different institutions over the last seven years. This talk will describe aspects of this mechanism, with particular emphasis on the biological role and chemical logic of the interference reaction.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {242},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974647,
author = {Weinberg, Zasha and Ruzzo, Walter L.},
title = {Faster genome annotation of non-coding RNA families without loss of accuracy},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974647},
doi = {10.1145/974614.974647},
abstract = {Non-coding RNAs (ncRNAs) are functional RNA molecules that do not code for proteins. Covariance Models (CMs) are a useful statistical tool to find new members of an ncRNA gene family in a large genome database, using both sequence and, importantly, RNA secondary structure information. Unfortunately, CM searches are slow. This paper shows how to make CMs faster while provably sacrificing none of their accuracy. Specifically, based on the CM, our software builds a profile hidden Markov model (HMM), which filters the genome database. This HMM is a gorous filter i.e., its filtering eliminates only sequences that provably could not be annotated as homologs. The CM is run only on what remains. Optimizing the HMM for filtering involves minimizing an exponential objective function with linear inequality constraints. For most known ncRNA families, this allows an 8-gigabase database to be scanned in 2-20 days instead of years, and yields new family members missed by other techniques to improve CM speed.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {243–251},
numpages = {9},
keywords = {rigorous filter, profile hidden Markov models, non-coding RNA, iron response element, hyperthermophile archaea snoRNA, histone downstream element, genome annotation, gene families, covariance models},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974648,
author = {Tang, Xinyu and Kirkpatrick, Bonnie and Thomas, Shawna and Song, Guang and Amato, Nancy M.},
title = {Using motion planning to study RNA folding kinetics},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974648},
doi = {10.1145/974614.974648},
abstract = {We propose a novel, motion planning based approach to approximately map the energy landscape of an RNA molecule. Our method is based on the successful probabilistic roadmap motion planners that we have previously successfully applied to protein folding. The key advantage of our method is that it provides a sparse map that captures the main features of the landscape and which can be analyzed to compute folding kinetics. In this paper, we provide evidence that this approach is also well suited to RNA. We compute population kinetics and transition rates on our roadmaps using the master equation for a few moderately sized RNA and show that our results compare favorably with results of other existing methods.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {252–261},
numpages = {10},
keywords = {motion planning, folding kinetics, RNA},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974649,
author = {Li, Haifeng and Jiang, Tao},
title = {A class of edit kernels for SVMs to predict translation initiation sites in eukaryotic mRNAs},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974649},
doi = {10.1145/974614.974649},
abstract = {The prediction of translation initiation sites (TISs) in eukaryotic mRNAs has been a challenging problem in computational molecular biology. In this paper, we present a new algorithm to recognize TISs with a very high accuracy. Our algorithm includes two novel ideas. First, we introduce a class of new sequence-similarity kernels based on string edit, called the edit kernels, for use with support vector machines (SVMs) in a discriminative approach to predict TISs. The edit kernels are simple and have significant biological and probabilistic interpretations. Second, we convert the region of an input mRNA sequence downstream to a putative TIS into an amino acid sequence before applying SVMs to avoid the high redundancy in the genetic code. The algorithm has been implemented and tested on previously published data. Our experimental results on real mRNA data show that both ideas improve the prediction accuracy greatly and our method performs significantly better than those based on neural networks and SVMs with polynomial kernels or Salzberg kernel.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {262–271},
numpages = {10},
keywords = {edit distance, mRNA, machine learning, positive definite kernel, support vector machine, translation initiation site},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974650,
author = {He, Xin and Goldwasser, Michael H.},
title = {Identifying conserved gene clusters in the presence of orthologous groups},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974650},
doi = {10.1145/974614.974650},
abstract = {Current biological evidence suggests a correlation between the function and the position of genes in chromosomes. Examples include operon structure in prokaryotic genomes and similar expression patterns of neighboring genes in some eukaryotic genomes. In this paper, we present a new model and algorithm for identifying conserved gene clusters from pairwise genome comparison. This generalizes a recent model called "gene teams." A gene team is a set of orthologous genes that appear in two or more species, possibly in a different order yet with the distance of adjacent genes in the team for each chromosome always no more than a certain threshold. We remove the constraint in the original model that each gene must have a unique copy in the chromosomes, and thus allow the analysis on complex prokaryotic or eukaryotic genomes with extensive paralogs. Our algorithm runs in O(mn) time and uses O(m+n) space, where m and n are the number of common genes in each chromosomes. We used this approach to study two bacterial genomes, E. coli and B. subtilis and successfully identified 85 conserved clusters, including clusters containing uncharacterized genes and a large cluster consisting of 21 ribosomal proteins. Our implementation is publicly available at http://euler.slu.edu/~goldwasser/cogteams/.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {272–280},
numpages = {9},
keywords = {bioinformatics, clusters of orthologous genes, comparative genomics, conserved gene clusters, gene teams},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974651,
author = {Doolittle, Russell F.},
title = {Fifty years of sequence analysis: what have we learned?},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974651},
doi = {10.1145/974614.974651},
abstract = {In 1955, not quite fifty years ago, Sanger's group published the first amino acid sequence of a protein, bovine insulin. Later that year, they reported sequences from sheep and pig, each of which showed a small number of differences from the bovine. Even earlier, sequences of several polypeptide hormones had been worked out, and their similarities and differences had already caught the eye of evolutionists. From this tiny amount of data sprang the hope, considered unrealistic by many at the time, that the histories of all living organisms might be reconstructed. Shortly thereafter, the notion that gene duplications were the source of most proteins was given a boost when the sequences of the alpha and beta chains of hemoglobin were reported to be more than 40 percent identical. By the 1960's, amino acid sequence analysis had taken hold as the major tool for determining the divergences of both creatures and their proteins. The obvious similarities of bacterial and eukaryotic enzyme sequences lent hope that the routes leading to all the major groups of organisms could be established, and the observation that proteins with different functions could have similar sequences showed that radical changes of function were possible. The paradigm that "all new proteins came from old proteins" became the dogma of the day. By the 1970's, the RNA sequencing of certain RNA moieties was almost routine, and the sequencing of numerous small subunit rRNAs revealed unexpectedly that there were three domains of life, now referred to as Archaea, Bacteria and Eukarya. The finding framed one of the major mysteries of all biology: which group came first and how are the others related to it? To this day the question has not been satisfactorily resolved. The advent of DNA sequencing in the late 1970's ushered in a new era, the deluge of data making all previous work seem trivial, even if fundamental questions remained. The campaign in the 1980's to sequence the human genome changed the nature of biological inquiry in a major way. Comparative genomics may indeed reveal the patterns of how the major life forms have evolved. Among recent successes using the genomic approach has been the unraveling and intertwining of proteins involved in photosynthesis and nitrogen fixation and their spread through the prokaryotic world. On another front, the history of protein folds is being analyzed with surprising clarity. The technological advances that have made all this possible--computers, robotics, photochemistry, and much more--are as mind-numbing as the results. But where are we going? What do we want to know? Although some of the evolutionary questions framed fifty years ago have been answered in part, many remain. What were the primordial proteins and how did they arise? What was the nature of the first cells? Although sequence analysis alone may not tell all, it has given us a great beginning.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {281},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974652,
author = {Sharan, Roded and Ideker, Trey and Kelley, Brian P. and Shamir, Ron and Karp, Richard M.},
title = {Identification of protein complexes by comparative analysis of yeast and bacterial protein interaction data},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974652},
doi = {10.1145/974614.974652},
abstract = {Mounting evidence shows that many protein complexes are conserved in evolution. Here we use conservation to find complexes that are common to yeast S. Cerevisiae and bacteria H. pylori. Our analysis combines protein interaction data, that are available for each of the two species, and orthology information based on protein sequence comparison. We develop a detailed probabilistic model for protein complexes in a single species, and a model for the conservation of complexes between two species. Using these models, one can recast the question of finding conserved complexes as a problem of searching for heavy subgraphs in an edge- and node-weighted graph, whose nodes are orthologous protein pairs.We tested this approach on the data currently available for yeast and bacteria and detected 11 significantly conserved complexes. Several of these complexes match very well with prior experimental knowledge on complexes in yeast only, and serve for validation of our methodology. The complexes suggest new functions for a variety of uncharacterized proteins. By identifying a conserved complex whose yeast proteins function predominantly in the nuclear pore complex, we propose that the corresponding bacterial proteins function as a coherent cellular membrane transport system. We also compare our results to two alternative methods for detecting complexes, and demonstrate that our methodology obtains a much higher specificity.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {282–289},
numpages = {8},
keywords = {bacteria, comparative analysis, conservation, heavy subgraph, probabilistic model, protein complex, protein interaction network, yeast},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974653,
author = {Meyerguz, Leonid and Kempe, David and Kleinberg, Jon and Elber, Ron},
title = {The evolutionary capacity of protein structures},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974653},
doi = {10.1145/974614.974653},
abstract = {In nature, one finds large collections of different protein sequences exhibiting roughly the same three-dimensional structure, and this observation underpins the study of structural protein families. In studying such families at a global level, a natural question to ask is how close to "optimal" the native sequences are in terms of their energy. We therefore define and compute the evolutionary capacity of a protein structure as the total number of sequences whose energy in the structure is below that of the native sequence. An important aspect of our definition is that we consider the space of all possible protein sequences, i.e. the exponentially large set of all strings over the 20-letter amino acid alphabet, rather than just the set of sequences found in nature.In order to make our approach computationally feasible, we develop randomized algorithms that perform approximate enumeration in sequence space with provable performance guarantees. We draw on the area of rapidly mixing Markov chains, by exhibiting a connection between the evolutionary capacity of proteins and the number of feasible solutions to the Knapsack problem. This connection allows us to design an algorithm for approximating the evolutionary capacity, extending a recent result of Morris and Sinclair on the Knapsack problem. We present computational experiments that show the method to be effective in practice on large collections of protein structures. In addition, we show how to use approximations to the evolutionary capacity to compute a statistical mechanics notion of "evolutionary temperature" on sequence space.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {290–297},
numpages = {8},
keywords = {approximate counting, evolutionary networks, protein structure, rapidly mixing Markov chains},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974654,
author = {Menke, Matthew and Scanlon, Eben and King, Jonathan and Berger, Bonnie and Cowen, Lenore},
title = {Wrap-and-pack: a new paradigm for beta structural motif recognition with application to recognizing beta trefoils},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974654},
doi = {10.1145/974614.974654},
abstract = {A method is presented that uses β-strand interactions at both the sequence and the atomic level, to predict the beta-structural motifs in protein sequences. A program called Wrap-and-Pack implements this method, and is shown to recognize β-trefoils, an important class of globular β-structures, in the Protein Data Bank with 92\% specificity and 92.3\% sensitivity in cross-validation. It is demonstrated that Wrap-and-Pack learns each of the ten known SCOP β-trefoil families, when trained primarily on β-structures that are not β-trefoils, together with 3D structures of known β-trefoils from outside the family. Wrap-and-Pack also predicts many proteins of unknown structure to be β-trefoils. The computational method used here may generalize to other β-structures for which strand topology and profiles of residue accessibility are well conserved.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {298–307},
numpages = {10},
keywords = {beta structures, beta trefoils, motif recognition, protein structure prediction, rotamer libraries, threading},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974655,
author = {Huan, Jun and Wang, Wei and Bandyopadhyay, Deepak and Snoeyink, Jack and Prins, Jan and Tropsha, Alexander},
title = {Mining protein family specific residue packing patterns from protein structure graphs},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974655},
doi = {10.1145/974614.974655},
abstract = {Finding recurring residue packing patterns, or spatial motifs, that characterize protein structural families is an important problem in bioinformatics. We apply a novel frequent subgraph mining algorithm to three graph representations of protein three-dimensional (3D) structure. In each protein graph, a vertex represents an amino acid. Vertex-residues are connected by edges using three approaches: first, based on simple distance threshold between contact residues; second using the Delaunay tessellation from computational geometry, and third using the recently developed almost-Delaunay tessellation approach.Applying a frequent subgraph mining algorithm to a set of graphs representing a protein family from the Structural Classification of Proteins (SCOP) database, we typically identify several hundred common subgraphs equivalent to common packing motifs found in the majority of proteins in the family. We also use the counts of motifs extracted from proteins in two different SCOP families as input variables in a binary classification experiment. The resulting models are capable of predicting the protein family association with the accuracy exceeding 90 percent. Our results indicate that graphs based on both almost-Delaunay and Delaunay tessellations are sparser than the contact distance graphs; yet they are robust and efficient for mining protein spatial motif.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {308–315},
numpages = {8},
keywords = {almost-delaunay, protein classification, subgraph mining},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974656,
author = {G\'{o}recki, Pawel},
title = {Reconciliation problems for duplication, loss and horizontal gene transfer},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974656},
doi = {10.1145/974614.974656},
abstract = {This paper presents a model of reconciling a species tree and a gene tree in an extended duplication-loss model. In the first part the definition of a model is introduced. In the second the horizontal transfer is defined and a new polynomial reconciliation algorithm is presented. We prove NP-completeness of the important problem related to the reconstruction of the species relationships with transfers from a given set of gene family trees. Some new problems are stated. We present a simple biological example.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {316–325},
numpages = {10},
keywords = {NP-completeness, duplication-loss model, horizontal gene transfer, reconciliation},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974657,
author = {Arvestad, Lars and Berglund, Ann-Charlotte and Lagergren, Jens and Sennblad, Bengt},
title = {Gene tree reconstruction and orthology analysis based on an integrated model for duplications and sequence evolution},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974657},
doi = {10.1145/974614.974657},
abstract = {Gene tree and species tree reconstruction, orthology analysis and reconciliation, are problems important in multigenome-based comparative genomics and biology in general. In the present paper, we advance the frontier of these areas in several respects and provide important computational tools. First, exact algorithms are given for several probabilistic reconciliation problems with respect to the probabilistic gene evolution model, previously developed by the authors. Until now, those problems were solved by MCMC estimation algorithms. Second, we extend the gene evolution model to the gene sequence evolution model, by including sequence evolution. Third, we develop MCMC algorithms for the gene sequence evolution model that, given gene sequence data allows: (1) orthology analysis, reconciliation analysis, and gene tree reconstruction, w.r.t. a species tree, that balances a likely/unlikely reconciliation and a likely/unlikely gene tree and (2) species tree reconstruction that balance a likely/unlikely reconciliation and a likely/unlikely gene trees. These MCMC algorithms take advantage of the exact algorithms for the gene evolution model. We have successfully tested our dynamical programming algorithms on real data for a biogeography problem. The MCMC algorithms perform very well both on synthetic and biological data.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {326–335},
numpages = {10},
keywords = {reconciliation, orthology, gene tree, bayesian analysis, algorithms},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974658,
author = {Lee, David and Grant, Alastair and Sillitoe, Ian and Dibley, Mark and Ranea, Juan Garcia and Orengo, Christine},
title = {A structural perspective on genome evolution},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974658},
doi = {10.1145/974614.974658},
abstract = {At UCL we have developed several automated protocols for generating protein family resources (CATH; Gene3D). These resources can be used to perform comparative genome analyses in order to understand the evolution of protein families. Also to identify biologically and/or medically interesting families for which no structural data currently exists and which may therefore be important targets for structure genomics initiatives.The CATH domain structure database, established by Orengo and Thornton in 1993, now contains a significant proportion of protein structures from the PDB clustered into 1400 evolutionary families. Relationships have been identified using robust structure comparison methods (SSAP, CATHEDRAL). We have also benchmarked and optimised various 1D-profiles and HMM based protocols for assigning genome sequences to families within the resource (e.g. SAM-T99, SAMOSA, CATH-ISL).In this way we can assign structural data to a large proportion (up to 60\%) of whole or partial sequences in completed genomes and &gt;80\% of genes coding for enzymes and other proteins in biochemical pathways. However, in order to include all families regardless of whether their structure is known or not, a new protein family resource has been developed (Gene3D). In Gene3D, complete genes have been clustered according to sequence similarity alone, using a robust clustering method (Pfscape). 120 completed genomes from all kingdoms have been clustered into 220,000 gene families, 70,000 of which contain 2 or more sequences. Subsequently, we have labelled those gene families for which CATH structural or Pfam functional domain annotations can be provided for all or part of the gene.Preliminary analysis of the genome annotations reveals that a significant proportion (up to 70\%) of CATH annotated genes or gene regions in genomes are assigned to domain families that are common to all three kingdoms of life. However, only 20\% of the genome sequences are assigned to gene families common to all kingdoms. Since a large proportion of these genes are multidomain proteins this supports the view that a great deal of functional diversity within the genomes has been achieved by combining domain modules in different ways.In collaboration with Professor Janet Thornton, we have analysed a subset of 56 bacterial genomes to determine the recurrence of specific domain structure families within the genomes. This revealed a small but essential group of universal, and in some cases, highly recurring domain families. For some size-dependent families, domain recurrence is highly correlated with increase in genome size, whilst in other size-independent families no correlation is observed. Statistical analysis allowed us to distinguish three groups. Within the size-dependent families we differentiated two groups: linearly-distributed and non-linearly-distributed. Functional annotation using the COGs revealed that these domains were predominantly involved in metabolism and regulation, respectively. Whilst a third group of Evenly-distributed size independent domains are primarily involved in protein translation and biosynthesis.By mapping CATH and Pfam domains families onto all the genome sequences in Gene3D we observe that a few hundred highly recurrent families are dominating at least 50\% of whole or partial genome sequences. Many of these families are common to both prokaryotes and eukaryotes and are performing essential generic functions. In many of the largest families, significant divergence in sequence has been accompanied by modifications in structure and function. Targetting representatives in these families for structure determination will allow the structure genomics initiatives to map both fold and function space and reveal the mechanisms by which divergence in protein families promotes evolution of new functions.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {336},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974659,
author = {Nakhleh, Luay and Warnow, Tandy and Linder, C. Randal},
title = {Reconstructing reticulate evolution in species: theory and practice},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974659},
doi = {10.1145/974614.974659},
abstract = {We present new methods for reconstructing reticulate evolution of species due to events such as horizontal transfer or hybrid speciation; both methods are based upon extensions of Wayne Maddison's approach in his seminal 1997 paper. Our first method is a polynomial time algorithm for constructing phylogenetic networks from two gene trees contained inside the network. We allow the network to have an arbitrary number of reticulations, but we limit the reticulation in the network so that the cycles in network are node-disjoint ("galled"); we prove accuracy guarantees for our first method by presenting a formal characterization of the set of gene trees defined by a species network. Our second method is a polynomial time algorithm for constructing networks with one reticulation, where we allow for errors in the estimated gene trees. Using simulations, we demonstrate improved performance of this method over both NeighborNet and Maddison's method.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {337–346},
numpages = {10},
keywords = {subtree prune and regraft, phylogenetic networks, gene trees},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974660,
author = {Hallett, Mike and Lagergren, Jens and Tofigh, Ali},
title = {Simultaneous identification of duplications and lateral transfers},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974660},
doi = {10.1145/974614.974660},
abstract = {This paper introduces a combinatorial model that incorporates duplication events as well as lateral gene transfer events (a.k.a. horizontal gene transfer events). To the best of our knowledge, this is the first such model containing both of these events. A so-called dt-scenario is used to explain differences between a gene tree T and species trees S. The model is biologically as well as mathematically sound. Among other biological considerations, the model respects the partial order of evolution implied by S by demanding that the dt-scenarios are "acyclic". We present fixed parameter tractable algorithms that count the minimum number of duplications and lateral transfers, and more generally can compute the set of pairs (t,d) where d is the minimum number of duplications required by any explanation that requires t lateral transfers. This allows us to also compute a weighted parsimony score. We also show how gene loss events can be incorporated into our model. We also give an $NP$-completeness proof which suggests that the intractability is due to the demand that the dt-scenarios be acyclic. When this condition is removed, we can show that the problem is computable in polynomial time via dynamic programming. By generating "synthetic" gene and species trees via a birth-death process, we explored the capacity of our algorithms to faithfully reconstruct the actual number of events taken place. The results are positive.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {347–356},
numpages = {10},
keywords = {lateral gene transfer, gene loss, gene duplication},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

@inproceedings{10.1145/974614.974661,
author = {Bustamante, Carlos},
title = {Recent advances on the manipulation of single biomolecules},
year = {2004},
isbn = {1581137559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/974614.974661},
doi = {10.1145/974614.974661},
abstract = {Over the last ten years, a number of new approaches have emerged that have made it possible for scientists to mechanically manipulate individual molecules. These methods are proving themselves quite powerful to investigate the molecular mechanisms underlying many dynamic biochemical processes. Because molecules are studied one at a time, single molecule manipulation techniques avoid the ensemble average characteristic of bulk studies. This feature is particularly useful to follow complex dynamic processes in time where the presence of multiple species in solution blurs the dynamical description of the system. Moreover, many processes in the cell are known to be mechanical in nature and mechanical force is one of the "products" of the reaction. It follows that forces applied to the molecules undergoing these processes can be used to alter the extent and in some cases even the fate of the reactions, thus helping to reveal the molecular mechanisms by which force is generated in them. In this presentation, I will illustrate the use of optical tweezers with three different examples taken from my own research.},
booktitle = {Proceedings of the Eighth Annual International Conference on Research in Computational Molecular Biology},
pages = {357},
numpages = {1},
location = {San Diego, California, USA},
series = {RECOMB '04}
}

